{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n        \nprint('\\n\\n\\n\\n\\n')\nfor dirname, _, filenames in os.walk('/kaggle/output'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T07:51:39.819637Z","iopub.execute_input":"2022-03-12T07:51:39.819922Z","iopub.status.idle":"2022-03-12T07:51:39.841460Z","shell.execute_reply.started":"2022-03-12T07:51:39.819884Z","shell.execute_reply":"2022-03-12T07:51:39.840736Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/majorproject-cse2022/loss_framework-2.png\n/kaggle/input/majorproject-cse2022/__results__.html\n/kaggle/input/majorproject-cse2022/accuracy_framework-2.png\n/kaggle/input/majorproject-cse2022/__notebook_source__.ipynb\n/kaggle/input/majorproject-cse2022/best_model_FrameWork1_Spam-Detection.hdf5\n/kaggle/input/majorproject-cse2022/__notebook__.ipynb\n/kaggle/input/majorproject-cse2022/accuracy_framework-1.png\n/kaggle/input/majorproject-cse2022/__output__.json\n/kaggle/input/majorproject-cse2022/best_model_FrameWork2_Spam-Detection.hdf5\n/kaggle/input/majorproject-cse2022/loss_framework-1.png\n/kaggle/input/majorproject-cse2022/custom.css\n/kaggle/input/majorproject-cse2022/__results___files/__results___249_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___273_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___258_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___244_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___264_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___274_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___259_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___263_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___243_0.png\n/kaggle/input/majorproject-cse2022/__results___files/__results___248_0.png\n/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\n/kaggle/input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\n/kaggle/input/spam-or-not-spam-dataset/spam_or_not_spam.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.50d.txt\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt\n/kaggle/input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\n/kaggle/input/fatsttext-common-crawl/crawl-300d-2M.vec\n/kaggle/input/fatsttext-common-crawl/crawl-300d-2M/crawl-300d-2M.vec\n\n\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **BUILDING MODEL IN OOPS WAY FOR BOTH SPAM/INAPP CONTENT DETECTION**\nThus this helps in providing abstraction and easy way to deploy model as well as will also help in providing an machine learning API for our proposed work. ","metadata":{}},{"cell_type":"code","source":"#Importing all the libraries \n\nprint(\"WORKING ON ML Models in object oriented way....\")\n\nimport time\nstart_time = time.time()\n# from numpy import asarray\n# from numpy import loadtxt\n# from numpy import savetxt\nimport pickle\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd, matplotlib.pyplot as plt \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.layers import Layer\nfrom keras.layers import InputSpec\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n# from keras.optimizers import  RMSprop, adam_v2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport_time = round((time.time()-start_time)*1000,3)\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\n\n\nprint(f\"'\\n\\nALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : {import_time} msec\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T07:51:43.468605Z","iopub.execute_input":"2022-03-12T07:51:43.468864Z","iopub.status.idle":"2022-03-12T07:51:43.479855Z","shell.execute_reply.started":"2022-03-12T07:51:43.468835Z","shell.execute_reply":"2022-03-12T07:51:43.479131Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"WORKING ON ML Models in object oriented way....\n'\n\nALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : 0.553 msec\n","output_type":"stream"}]},{"cell_type":"code","source":"class RocAucEvaluation(Callback):\n    '''\n     Customized Class to handle ROC AUC Evaluation for each epoch and printing epoch number and score for each epoch which is multiple of interval.  \n    '''\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n\n#################################################################################################################################################\n\nclass Modelbase :\n    def __init__(self, embed_size = 300, max_features = 130000, max_len = 220, model_Type = \"Spam-Detection\", *args, **kwargs,):\n        self.model_Type = model_Type\n        self.embed_size = embed_size\n        self.max_features = max_features #Vocabulary Size \n        self.max_len = max_len  # maximum length of tweet. \n        self.X_train = None\n        self.Y_train = None\n        self.X_valid = None\n        self.Y_valid = None\n        self.train = None\n        self.y = None\n        self.raw_text_train = None \n        self.raw_text_valid= None\n        if self.model_Type == \"Spam-Detection\":\n            self.list_classes = [\"ham\", \"spam\"]\n            self.tweet_column = \"Message\"\n            self.train_df1 = None\n            self.train_df2 = None            \n        else:\n            self.list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n            self.tweet_column = \"comment_text\"\n            self.test = None\n            self.raw_test_valid= None        \n            self.X_test =  None\n            \n        \n    def read_dataset(self,filepath):\n        '''\n        Reading the training and testing data i.e converting that into dataframes\n        input : file path \n        ----------------\n        output : dataframe \n        '''\n        df = pd.read_csv(filepath)\n        return df \n    \n    def build_train_test_dev_set(self, \n                                 trainDF1 = \"../input/spam-or-not-spam-dataset/spam_or_not_spam.csv\" , \n                                 trainDF2 = \"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\" , \n                                 trainDF  = \"../input/jigsaw-toxic-comment-classification-challenge/train.csv\" , \n                                 testDF   = \"../input/jigsaw-toxic-comment-classification-challenge/test.csv\"  ):\n        \n        if self.model_Type == \"Spam-Detection\"  :\n            self.train_df1 = self.read_dataset(trainDF1)\n            self.train_df2 = self.read_dataset(trainDF2)\n            self.spam_Dataset_Aggregator()\n            self.train = self.train.dropna()\n            return \n        else:    \n            self.train  = self.read_dataset(trainDF)\n            self.test  = self.read_dataset(testDF)\n#             self.train = self.train.dropna()\n            return\n        \n    def spam_Dataset_Aggregator(self):\n        self.train_df1.rename( columns={self.train_df1.columns[0] : \"Message\", self.train_df1.columns[1] : \"Category\" },inplace=True)\n        self.train_df2[self.train_df2.columns[0]].replace({\"ham\": 0, \"spam\": 1}, inplace=True)\n        self.train_df2 = self.train_df2[ [ self.train_df2.columns[1], self.train_df2.columns[0] ] ]\n        self.train = pd.concat([self.train_df1, self.train_df2], ignore_index=True, sort=False)\n        return  \n        \n    def __repr__(self):\n        if self.model_Type == \"Spam-Detection\":\n            return f\"Model for Spam Detection (Ham/Spam detection) \\n Model Type :  {self.model_Type}\"\n        return f\"Model for Inappropraue Content Detection (Ham/Spam detection) \\n Model Type :  {self.model_Type}\" #Inappropriate-Content-Detection\n\n    \n    \n#######################################################################################################################################################\n\n\n\nclass Preprocessor(Modelbase):\n    \n    def __init__(self,embed_size = 300, \n                 max_features = 130000, \n                 max_len = 220, \n                 model_Type = \"Spam-Detection\", \n                 *args, **kwargs):\n#         super(Model, self).__init__()\n        super().__init__(embed_size , max_features, max_len, model_Type)\n        # num_words = the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n        self.tk = Tokenizer(num_words = max_features)\n        self.embedding_matrix_fastText = None\n        self.embedding_matrix_glove = None\n        self.embedding_index_fastText = None\n        self.embedding_index_glove = None\n        self.embedding_matrix_fastText_shape = None\n        self.embedding_matrix_glove_shape = None\n#         self.embedding_index_fastText_shape = None\n#         self.embedding_index_glove_shape = None\n        \n    def train_test_splitter(self,validation_size=0.1):\n        '''\n        Input : training dataset Dataframe -> train\n        ------------\n        Output : Training and dev dataframe with X and Y values along with raw train and dev set with all comments in lower.\n        '''\n        if self.model_Type != \"Spam-Detection\" :\n            # y = np.asarray(y).astype(np.float32)\n            self.y = self.train[self.list_classes].values\n            self.train[self.tweet_column].fillna(\"no comment\")\n            self.test[self.tweet_column].fillna(\"no comment\") \n#             self.train = self.train.dropna()  #**********************************************************\n        else:\n            self.y = self.train[\"Category\"].values\n            # y = np.asarray(y).astype(np.float32)\n            self.train[self.tweet_column].fillna(\"no comment\")\n        # train_df2[\"Message\"].fillna(\"no comment\")\n        validation_size = validation_size   #by default it is 0.1\n        # splitting train:dev -->  9:1 so train consist of 90 percent and validation set consist of 10 percent of entire training data \n        #Note : This validation_size is configurable and can be changed later.\n        self.X_train, self.X_valid, self.Y_train, self.Y_valid = train_test_split(self.train, self.y, test_size = validation_size)\n        # Lowering all the comments of training, validation and test data let callled it as raw.\n        self.raw_text_train = self.X_train[self.tweet_column].str.lower()\n        self.raw_text_valid = self.X_valid[self.tweet_column].str.lower()\n        if self.model_Type != \"Spam-Detection\" :\n            self.raw_test_valid = self.test[self.tweet_column].str.lower()\n        return\n\n    def tokenizer(self):\n            '''\n            Input : raw train and dev set along with in-rawed train and dev set.\n            --------------------------------------------------------------------------------\n            Output: tokenizer object along with padded and sequenced training and validation dataset\n            '''\n            # Article for better undrstanding of Tokenizer : https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/\n            #Tokeinzing the raw training set\n            self.tk.fit_on_texts(self.raw_text_train)\n            print(self.raw_text_train.shape )\n            self.X_train[self.tweet_column] = self.tk.texts_to_sequences(self.raw_text_train)\n            self.X_valid[self.tweet_column] = self.tk.texts_to_sequences(self.raw_text_valid)\n            self.X_train = pad_sequences(self.X_train[self.tweet_column], maxlen = self.max_len)\n            self.X_valid = pad_sequences(self.X_valid[self.tweet_column], maxlen = self.max_len)\n            if self.model_Type != \"Spam-Detection\" :\n                self.test[self.tweet_column] = self.tk.texts_to_sequences(self.raw_test_valid )\n                self.test = pad_sequences(self.test[self.tweet_column], maxlen = self.max_len) #test.comment_seq\n            return\n    \n    def get_coefs(self,word,*arr): \n        '''\n        Creating Embeeding Index which can help further to create embedding matrix for the words in our training dataset vocabulary.\n        This Ebedding index is created from the fastText or Glove.\n        '''\n        return word, np.asarray(arr, dtype='float32')\n    \n    \n    def embeeding_Index_Builder(self, embedding_path):\n        '''\n        Embedding Index correpsonding to embeddding Path\n        Input : embeddig path \n        ----------------------\n        Output : embedding Index\n        '''\n        embedding_index = dict(self.get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n        return embedding_index\n\n    def embeeding_Matrix_Builder(self,embedding_index ):\n        '''\n        Input : tokenizer object , with maximum features and embedding size along with fastText and Glove Embedding Index for building Embeeding Matrix\n        ----------------------------------------------------------------------------------------------------------------------------------------------\n        Output: embedding matix corresponding to FastText and Glove\n        '''\n        # Preparing Our Embeeding matrix from Embedding Index from glove or fastText or any other index. \n        damword_index = self.tk.word_index\n        nb_words = min(self.max_features, len(damword_index))\n        embedding_matrix = np.zeros((nb_words+1, self.embed_size))\n        for word, i in damword_index.items():\n            if i >= self.max_features: continue\n            embedding_vector = embedding_index.get(word)\n            if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n        return embedding_matrix\n    \n    def save_embeeding_index_or_matrix_as_csv(self, embedding_index_or_matrix, arrayType=\"index\", embeddingType=\"FastText\"):\n        # save numpy array embeeding_index as csv file\n        # define data\n        if arrayType!=\"index\":\n            data = copy.deepcopy(embedding_index_or_matrix)\n            # save to csv file\n            data = data.ravel()\n            np.savetxt(f'embedding_{arrayType}_{embeddingType}.csv', data, delimiter=',')\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"wb\")\n            pickle.dump(embedding_index_or_matrix, a_file)\n            a_file.close() \n        \n    def load_embedding_index_or_matrix_from_csv(self, arrayType=\"index\", embeddingType=\"FastText\"):\n        # load numpy array  embeeding_index from csv file\n        # load array\n        if arrayType!=\"index\":\n            data = np.loadtxt(f'embedding_{arrayType}_{embeddingType}.csv', delimiter=',')\n            reshaped_data = None\n\n            if embeddingType==\"FastText\" :\n#                 if arrayType==\"index\":\n                reshaped_data = np.reshape(data,self.embedding_index_fastText_shape )\n#                 else:\n#                     reshaped_data = np.reshape(data,self.embedding_matrix_fastText_shape )\n            elif embeddingType==\"Glove\":\n#                 if arrayType==\"index\":\n                reshaped_data = np.reshape(data,self.embedding_index_glove_shape )\n#                 else:\n#                     reshaped_data = np.reshape(data,self.embedding_matrix_glove_shape )\n            # print the array\n            return reshaped_data\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"rb\")\n            output = pickle.load(a_file)\n            return output\n\n            \n    \n    def save_embeeding_index_or_matrix_as_binary(self, embedding_index_or_matrix , arrayType=\"index\", embeddingType=\"FastText\"):\n        # save numpy array embeeding_index as binary file npy\n        # define data\n        if arrayType!=\"index\":\n            np.save(f'embedding_{arrayType}_{embeddingType}.npy', embedding_index_or_matrix )\n            return\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"wb\")\n            pickle.dump(embedding_index_or_matrix, a_file)\n            a_file.close() \n        \n    def load_embedding_index_or_matrix_from_binary(self, arrayType=\"index\", embeddingType=\"FastText\"):\n        # load numpy array  embeeding_index from npy file\n        # load array\n        if arrayType!=\"index\":\n            data = np.load(f'embedding_{arrayType}_{embeddingType}.csv')\n            return data\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"rb\")\n            output = pickle.load(a_file)\n            return output\n\n\n    def preprocessing(self, \n                      validation_size=0.1,\n                      embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\",\n                      embedding_path_glove =\"../input/glove840b300dtxt/glove.840B.300d.txt\",\n                      isEmbeddingIndexFileSaved     =False,\n                      isEmbeddingMatrixFileSaved    = False,\n                      wantToSaveEmbeedingIndexFile  = False,\n                      wantToSaveEmbeedingMatrixFile = False ):\n        self.build_train_test_dev_set()\n        print('Building Trainning and Testing is Done.')\n        self.train_test_splitter(validation_size)\n        print('Spliting Trainning and Testing is Done.')\n        self.tokenizer()\n        print('Tokenizing is Done.')\n        if not isEmbeddingIndexFileSaved :\n            self.embedding_index_fastText = self.embeeding_Index_Builder(embedding_path_fastText)\n            print('Embeeding Index for Fasttext is Done.')\n            self.embedding_index_glove = self.embeeding_Index_Builder(embedding_path_glove)\n            print('Embeeding Index for Glove is Done.')\n            if wantToSaveEmbeedingIndexFile:\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_index_fastText  , arrayType=\"index\", embeddingType=\"FastText\")\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_index_glove  , arrayType=\"index\", embeddingType=\"Glove\")\n        else:\n            self.embedding_index_fastText  = self.load_embedding_index_or_matrix_from_binary(arrayType=\"index\", embeddingType=\"FastText\")\n            self.embedding_index_glove  = self.load_embedding_index_or_matrix_from_binary(arrayType=\"index\", embeddingType=\"Glove\")\n#         self.embedding_index_fastText_shape = self.embedding_index_fastText.shape\n#         self.embedding_index_glove_shape = self.embedding_index_glove.shape\n        \n        if not isEmbeddingMatrixFileSaved :\n            self.embedding_matrix_fastText = self.embeeding_Matrix_Builder( self.embedding_index_fastText )\n            print(f'Embedding Matrix for FastText is Done., with it\\'s shape as {self.embedding_matrix_fastText_shape}')\n            self.embedding_matrix_glove = self.embeeding_Matrix_Builder( self.embedding_index_glove )\n            print(f'Embedding Matrix for Glove is Done with shape as { self.embedding_matrix_glove_shape}')\n            if  wantToSaveEmbeedingMatrixFile:\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_matrix_fastText , arrayType=\"matrix\", embeddingType=\"FastText\")\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_matrix_glove   , arrayType=\"matrix\", embeddingType=\"Glove\")\n        else:\n            self.embedding_matrix_fastText  = self.load_embedding_index_or_matrix_from_binary(arrayType=\"matrix\", embeddingType=\"FastText\")\n            self.embedding_matrix_glove     = self.load_embedding_index_or_matrix_from_binary(arrayType=\"matrix\", embeddingType=\"Glove\")\n#         self.embedding_matrix_fastText_shape = self.embedding_matrix_fastText.shape\n#         self.embedding_matrix_glove_shape =  self.embedding_matrix_glove.shape \n        return\n    \n#######################################################################################################################################################\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T07:51:48.877193Z","iopub.execute_input":"2022-03-12T07:51:48.877450Z","iopub.status.idle":"2022-03-12T07:51:48.926400Z","shell.execute_reply.started":"2022-03-12T07:51:48.877421Z","shell.execute_reply":"2022-03-12T07:51:48.925560Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ML_Model :\n    def __init__(self, \n                 ModelBaseInstance = Preprocessor( embed_size = 300, \n                                           max_features = 130000, \n                                           max_len = 220, \n                                           model_Type = \"Spam-Detection\"),\n#                  embed_size = 300, \n#                  max_features = 130000, \n#                  max_len = 220, \n#                  model_Type = \"Spam-Detection\", \n                 file_path = \"1\",\n                 n_multiClassificationClasses = 1 ,# if Inappropriate then 6 as they are : \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n                 *args, **kwargs):  # for file_path just pass which idea/framework on which this Model is based upon\n#         super(Preprocessor, self).__init__()\n#         super().__init__( embed_size = 300, \n#                           max_features = 130000, \n#                           max_len = 220, \n#                           model_Type = \"Spam-Detection\")\n        self.modelBase = ModelBaseInstance\n        self.model = None\n        self.history = None\n        self.framework_idea = file_path \n        self.file_path = \"best_model_\" + \"FrameWork\" + self.framework_idea + \"_\" + self.modelBase.model_Type  + \".hdf5\" \n        self.check_point = ModelCheckpoint(self.file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n        self.ra_val = None\n        #Allowing early stopping\n        self.early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n        self.n_output_nuerons = n_multiClassificationClasses\n        \n    def change_idea_for_same_object(self,change_idea_to=\"2\", automatic_train = False, *args, **kwargs):\n        earlier_idea = self.framework_idea \n        self.framework_idea = change_idea_to\n        self.file_path = \"best_model_\" + \"FrameWork\" + self.framework_idea + \"_\" + self.modelBase.model_Type + \".hdf5\" \n        self.check_point = ModelCheckpoint(self.file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n        print(f\"Framework is changeed succesfully \\n Idea/Frameowkr earlier :  {earlier_idea} \\n Idea/Framework Now {self.framework_idea } : \")\n        print(\"\\n\\n PS: This method will keep in handy when you want to test for multiple idea without doing preprocessing step again.\")\n        # TO-DO  allo training auto to be done for user given parameters\n        if automatic_train:\n            print(f\"Note: The training is requested to be done AUTOMATICALLY as automatic_train flag is {automatic_train}, Note:  This training will be done on default parameters \\n i.e lr = 0.0, \\n lr_d = 0.0, \\n units = 0, \\n dr = 0.0, \\n epochs=10.\")\n            print('OR The parameters which was set for earlier IDEA/FRAMEWORK')\n            self.train_Model()\n        else:\n            print(\"\\t Note : WE NEED TO RE-TRAINED THE MODEL.\\n\\n \\t For Help :: USE METHOD --> train_Model for this in order to train the model on new Idea/Framework. \\n \\t Not training automatically as Automatic train Flag is off.\")\n        return\n    \n    def roc_Auc_Valuation(self):\n        self.ra_val = RocAucEvaluation(validation_data=(self.modelBase.X_valid, self.modelBase.Y_valid), interval = 1)\n        return\n        \n    def build_model_framework1(self, lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n        inp = Input(shape = (self.modelBase.max_len,))\n#         x_fastText = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n#         x_glove = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n        x_fastText = Embedding(self.modelBase.embedding_matrix_fastText.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n        x_glove = Embedding(self.modelBase.embedding_matrix_glove.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n        \n    \n    #Drop-Out Layer\n        x1_fastText = SpatialDropout1D(dr)(x_fastText)\n        x1_glove = SpatialDropout1D(dr)(x_glove)\n        #BI-LSTM BRANCH\n        x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #BI-GRU BRNACH\n        x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n        #Bi-listm\n        x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n        x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n        x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n        #concatenating\n        x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n\n        x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n        x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n        x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n        #concatenating\n        x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n        #Bi-gru\n        x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n        x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n        x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n        #concatenating\n        x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n        x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n        x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n        x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n        #concatenating\n        x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n        #Con-Catenating Bi-Lstm branch\n        x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n        #Con-Catenating Bi-Gru branch\n        x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n        #ConCatenating Bi-LSTM and Bi-GRU Branch\n        x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n        #Passing concatenated output to dense network\n    #     xxxx = Dense(8, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    #     xxx = Dense(4, activation = \"sigmoid\")(xxxx)\n    #     xx = Dense(2, activation = \"sigmoid\")(xx)\n    #     x = Dense(1, activation = \"sigmoid\")(xx) \n        \n#         if self.model_Type != \"Spam-Detection\" :\n#             assert self.n_output_nuerons==6\n#         else:\n#             assert self.n_output_nuerons==1\n\n        print(self.n_output_nuerons)\n            \n        x = Dense(self.n_output_nuerons, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n        self.model = Model(inputs = inp, outputs = x)\n        self.model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    #     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    \n#         print(\"*************************************************\")\n#         print(f\"Y_train's size/shape  ={self.modelBase.Y_train.shape} \")\n#         print(f\"Y_valid's size/shape  ={self.modelBase.Y_valid.shape} \")  \n        \n        self.history = self.model.fit(self.modelBase.X_train, self.modelBase.Y_train, batch_size = 128, epochs = epochs, validation_data = (self.modelBase.X_valid, self.modelBase.Y_valid), \n                            verbose = 1, callbacks = [self.ra_val, self.check_point, self.early_stop])\n        self.model = load_model(self.file_path)\n        return\n        \n    def build_model_framework2(self,lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n        inp = Input(shape = (self.modelBase.max_len,))\n#         x_fastText = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n#         x_glove = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n\n        x_fastText = Embedding(self.modelBase.embedding_matrix_fastText.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n        x_glove = Embedding(self.modelBase.embedding_matrix_glove.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n       \n    #Drop-Out Layer\n        x1_fastText = SpatialDropout1D(dr)(x_fastText)\n        x1_glove = SpatialDropout1D(dr)(x_glove)\n        #BI-LSTM BRANCH\n        x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #BI-GRU BRNACH\n        x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n        #Bi-listm\n        x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n        x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n        x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n        #concatenating\n        x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n\n        x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n        x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n        x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n        #concatenating\n        x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n        #Bi-gru\n        x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n        x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n        x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n        #concatenating\n        x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n\n        x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n        x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n        x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n        #concatenating\n        x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n        #Con-Catenating Bi-Lstm branch\n        x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n        #Con-Catenating Bi-Gru branch\n        x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n        #ConCatenating Bi-LSTM and Bi-GRU Branch\n        x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n        #Passing concatenated output to dense network\n    #     xxxx = Dense(8, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    #     xxx = Dense(4, activation = \"sigmoid\")(xxxx)\n    #     xx = Dense(2, activation = \"sigmoid\")(xxx)\n    #     x = Dense(1, activation = \"sigmoid\")(xx)\n    \n        print(self.n_output_nuerons)\n\n        x = Dense(self.n_output_nuerons, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n        self.model = Model(inputs = inp, outputs = x)\n        self.model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    #     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n        self.history = self.model.fit(self.modelBase.X_train, self.modelBase.Y_train, batch_size = 128, epochs = epochs, validation_data = (self.modelBase.X_valid, self.modelBase.Y_valid), \n                            verbose = 1, callbacks = [self.ra_val, self.check_point, self.early_stop])\n        self.model = load_model(self.file_path)\n        return \n    \n    def build_model_framework3(self,lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n        pass\n    \n    def build_model(self, lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 30):\n        self.roc_Auc_Valuation()\n        if self.framework_idea == \"1\":\n            self.build_model_framework1( lr, lr_d , units, dr ,epochs)\n        elif self.framework_idea == \"2\":\n            self.build_model_framework2( lr, lr_d , units, dr ,epochs)\n        else : \n            self.build_model_framework3( lr, lr_d , units, dr ,epochs)\n        \n    def train_Model(self, lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 30):\n        #For training use this member function\n        print(\"TRAINING STARTED\")\n        self.build_model(lr , lr_d, units, dr ,epochs)\n        print(\"TRAINING COMPLETED\")\n    \n    def get_accuracy_for_validation_set(self):\n        return self.prediction(self.modelBase.X_valid, self.modelBase.Y_valid)\n        \n    def get_accuracy_for_training_set(self):\n        return self.prediction(self.modelBase.X_train, self.modelBase.Y_train)\n         \n    def Plot(self, string): # example Object.Plot(history, \"accuracy\")  or Object.Plot(history, \"loss\")\n        plt.plot(self.history.history[string])\n        plt.plot(self.history.history['val_' + string])\n        plt.xlabel(\"EPOCHS\")\n        plt.ylabel(string)\n        plt.legend([string, 'val_' + string ])\n        plt.savefig(string + \"_framework-\" + self.framework_idea  +'_' + self.modelBase.model_Type  + '_'+'.png')\n        plt.show()       \n        print(f\"###### DONE PLOTTING FOR IDEA - {self.framework_idea} ########\")\n                    \n    def prediction(self,dataset, y_actual,on_the_fly=0 ): # On the fly is for those data that is comimg on the fly from any tweet.\n        y_pred_validation = self.model.predict(dataset, verbose=1)\n        score_validation = roc_auc_score(y_actual, y_pred_validation)\n        print(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")\n        return y_pred_validation\n        \n##############################################################################################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-03-12T07:52:15.992360Z","iopub.execute_input":"2022-03-12T07:52:15.992659Z","iopub.status.idle":"2022-03-12T07:52:16.044182Z","shell.execute_reply.started":"2022-03-12T07:52:15.992628Z","shell.execute_reply":"2022-03-12T07:52:16.043375Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Importing required libraries \nimport pickle, time\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd, matplotlib.pyplot as plt \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Model, load_model\nimport logging\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nclass PredictorObject:\n    def __init__(self, max_len=220, \n                     max_features = 130000,\n                     model_Type = \"Spam-Detection\",\n                     file_path = \"1\",\n                    n_multiClassificationClasses = 1,# if Inappropriate then 6 as they are : \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n                    tweet_column = None,\n                     *args, **kwargs):\n        self.start_time = time.time        \n        self.max_features = max_features\n        self.max_len = max_len\n        self.n_multiClassificationClasses  = n_multiClassificationClasses         \n        self.model_instanc_type = model_Type \n        self.framework_idea = file_path \n        self.tk = Tokenizer(num_words = self.max_features, lower = True)\n        self.file_path = \"best_model_\" + \"FrameWork\" + self.framework_idea + \"_\" + self.model_instanc_type  + \".hdf5\"\n        self.result_filename = \"RESULTS.csv\"\n        \n        #check whether model is already prsent else load the model\n        self.model = load_model(self.file_path)\n        \n        self.tweet = None\n        self.tweet_array = None\n        self.tweet_df = None\n        self.raw_tweet_df = None\n        ######??\n        self.preprocessor_module = None\n        self.tweet_column,  self.list_classes = (\"Email-Text\", [\"ham-or-spam\"] ) if self.model_instanc_type == \"Spam-Detection\" else (\"Tweet-Comment\" , [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"] )  \n        if tweet_column :\n            self.tweet_column = tweet_column\n        self.result = pd.DataFrame(columns = list(self.tweet_column ) + self.list_classes) \n\n    def initializeAll(self):\n        self.tweet = None\n        self.tweet_array = None\n        self.tweet_df = None\n        self.raw_tweet_df = None\n        self.tweet_column,  self.list_classes = (\"Email-Text\", [\"ham-or-spam\"] ) if self.model_instanc_type == \"Spam-Detection\" else (\"Tweet-Comment\" , [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"] )            \n        self.preprocessor_module = None\n        self.result = pd.DataFrame(columns = list(self.tweet_column ) + self.list_classes) \n        self.result_filename = \"RESULTS.csv\"\n        \n    def reLoadModel(self):\n        #check whether model is already prsent else load the model\n        self.model = load_model(self.file_path)\n        return\n        \n    def prediction(self, tweet_data=None, isText=True, isArray=False, isDataFrame=False, path_to_Tweet_DataFrame=None, result_filename=None ):\n        def exor(a, b): return ( a&(~b) or b&(~a) )        \n        if ( not exor( exor(isText, isArray), isDataFrame ) ) or ( isText == isArray and isText==isDataFrame ) :\n            print('404: all three or any two can not be true only one paramenters among isTweet, isDataFrame, isArray will be only true' )\n            return\n        if isText:\n            self.tweet = tweet_data\n            self.tweet_array = list(tweet_data)\n            y_pred = self.preprocessDataFrame()\n        elif isArray:\n            self.tweet = None\n            self.tweet_array = tweet_data\n            y_pred = self.preprocessDataFrame()\n        else:\n            if path_to_Tweet_DataFrame :\n                self.tweet_df =  pd.read_csv(path_to_Tweet_DataFrame)\n                y_pred = self.preprocessDataFrame( override=True )\n            else:\n                print('ERROR : 404 FILE NOT FOUND!!! Provide valid path name.')\n                return\n        if not result_filename:\n            self.result_filename = result_filename\n        self.result[self.tweet_column] = (self.tweet_df[self.tweet_column ])\n        self.result[self.list_classes] =  (y_pred)\n        self.result.to_csv(self.result_filename, index = False )\n        print(\"[{}] Completed!\".format(time.time() - self.start_time))\n        return (self.result, self.tweet_column, self.list_classes, self.result_filename) \n\n    \n    def preprocessDataFrame(self,override=False):\n        if not override:\n            self.tweet_df = pd.DataFrame( self.tweet_array, columns = [ self.tweet_column ])\n        self.tweet_df[self.tweet_column].fillna(\"no comment\")\n        self.raw_tweet_df = self.tweet_df[self.tweet_column].str.lower()\n        self.tweet_df[ self.tweet_column ] = self.tk.texts_to_sequences( self.raw_tweet_df )\n        self.tweet_df = pad_sequences( self.tweet_df[ self.tweet_column ], maxlen = self.max_len ) \n        y_pred = self.model.predict(self.tweet_df, verbose=0)\n        return y_pred","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-12T09:25:56.492633Z","iopub.execute_input":"2022-03-12T09:25:56.492906Z","iopub.status.idle":"2022-03-12T09:25:56.516734Z","shell.execute_reply.started":"2022-03-12T09:25:56.492876Z","shell.execute_reply":"2022-03-12T09:25:56.516030Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# class PredictorObject:\n#     def __init(self, max_len=220, \n#                      max_features = 130000,\n#                      model_Type = \"Spam-Detection\",\n#                      file_path = \"1\",\n#                     n_multiClassificationClasses = 1,# if Inappropriate then 6 as they are : \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n#                     *args, **kwargs):\n#         self.start_time = time.time        \n#         self.max_features = max_features\n#         self.max_len = max_len\n#         self.n_multiClassificationClasses  = n_multiClassificationClasses         \n#         self.model_instanc_type = model_Type \n#         self.framework_idea = file_path \n#         self.tk = Tokenizer(num_words = self.max_features, lower = True)\n#         self.file_path = \"best_model_\" + \"FrameWork\" + self.framework_idea + \"_\" + self.model_instanc_type  + \".hdf5\"\n        \n#         #check whether model is already prsent else load the model\n#         self.model = load_model(self.file_path)\n        \n#         self.tweet = None\n#         self.tweet_array = None\n#         self.tweet_df = None\n#         self.raw_tweet_df = None\n#         self.preprocessor_module = None\n#         self.tweet_columns,  self.list_classes = (\"Email-Text\", [\"ham-or-spam\"] ) if self.model_instanc_type == \"Spam-Detection\" else (\"Tweet-Comment\" , [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"] )            \n\n#     def initializeAll(self):\n#         self.tweet = None\n#         self.tweet_array = None\n#         self.tweet_df = None\n#         self.raw_tweet_df = None\n#         self.tweet_columns = \"Tweet-Comment\" if self.model_instanc_type != \"Spam-Detection\" else \"Email-Text\" \n#         self.preprocessor_module = None\n        \n#     def prediction(self, tweet_data, isText=True, isArray=False, isDataFrame=False ):\n#         def exor(a, b): return ( a&(~b) or b&(~a)           \n#         if ( not exor( exor(isText, isArray), isDataFrame ) )or ( isText == isArray and isText==isDataFrame ) :\n#             reurn '404: all three or any two can not be true only one paramenters among isTweet, isDataFrame, isArray will be only true' \n#         if isText:\n#             self.tweet = tweet_data\n#             self.tweet_array = list(tweet_data)\n#             y_pred = self.preprocessDataFram()\n#         elif isArray:\n#         else:\n#         self.submission[list_classes] = (y_pred)\n#         submission.to_csv(\"submission.csv\", index = False)\n#         print(\"[{}] Completed!\".format(time.time() - self.start_time))\n            \n# #         submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n#         self.tweet_array or self.tweet = None #'given tweet array or convert it into an array'\n#         pass\n    \n#     def preprocessDataFrame(self):\n#         self.tweet_df = pd.DataFrame( self.tweet_array, columns = [ self.tweet_columns ])\n#         self.tweet_df[self.tweet_column].fillna(\"no comment\")\n#         self.raw_tweet_df = self.tweet_df[self.tweet_column].str.lower()\n#         self.tweet_df[ self.tweet_column ] = self.tk.texts_to_sequences( self.raw_tweet_df )\n#         self.tweet_df = pad_sequences( self.tweet_df[ self.tweet_column ], maxlen = self.max_len ) \n#         y_pred = self.model.predict(self.tweet_df, verbose=0)\n#         return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:26:02.719541Z","iopub.execute_input":"2022-03-12T09:26:02.721156Z","iopub.status.idle":"2022-03-12T09:26:02.733123Z","shell.execute_reply.started":"2022-03-12T09:26:02.721105Z","shell.execute_reply":"2022-03-12T09:26:02.731642Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv')\n\ndf_test = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:26:05.352234Z","iopub.execute_input":"2022-03-12T09:26:05.352700Z","iopub.status.idle":"2022-03-12T09:26:07.035748Z","shell.execute_reply.started":"2022-03-12T09:26:05.352662Z","shell.execute_reply":"2022-03-12T09:26:07.035032Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:28:32.874807Z","iopub.execute_input":"2022-03-12T08:28:32.875195Z","iopub.status.idle":"2022-03-12T08:28:32.893353Z","shell.execute_reply.started":"2022-03-12T08:28:32.875159Z","shell.execute_reply":"2022-03-12T08:28:32.892473Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                 id  toxic  severe_toxic  obscene  threat  insult  \\\n0  00001cee341fdb12    0.5           0.5      0.5     0.5     0.5   \n1  0000247867823ef7    0.5           0.5      0.5     0.5     0.5   \n2  00013b17ad220c46    0.5           0.5      0.5     0.5     0.5   \n3  00017563c3f7919a    0.5           0.5      0.5     0.5     0.5   \n4  00017695ad8997eb    0.5           0.5      0.5     0.5     0.5   \n5  0001ea8717f6de06    0.5           0.5      0.5     0.5     0.5   \n6  00024115d4cbde0f    0.5           0.5      0.5     0.5     0.5   \n7  000247e83dcc1211    0.5           0.5      0.5     0.5     0.5   \n8  00025358d4737918    0.5           0.5      0.5     0.5     0.5   \n9  00026d1092fe71cc    0.5           0.5      0.5     0.5     0.5   \n\n   identity_hate  \n0            0.5  \n1            0.5  \n2            0.5  \n3            0.5  \n4            0.5  \n5            0.5  \n6            0.5  \n7            0.5  \n8            0.5  \n9            0.5  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0001ea8717f6de06</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>00024115d4cbde0f</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>000247e83dcc1211</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>00025358d4737918</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>00026d1092fe71cc</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_test","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:28:39.738629Z","iopub.execute_input":"2022-03-12T08:28:39.738884Z","iopub.status.idle":"2022-03-12T08:28:39.750647Z","shell.execute_reply.started":"2022-03-12T08:28:39.738855Z","shell.execute_reply":"2022-03-12T08:28:39.749882Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text\n0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n3  00017563c3f7919a  :If you have a look back at the source, the in...\n4  00017695ad8997eb          I don't anonymously edit articles at all.","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00001cee341fdb12</td>\n      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0000247867823ef7</td>\n      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00013b17ad220c46</td>\n      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00017563c3f7919a</td>\n      <td>:If you have a look back at the source, the in...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017695ad8997eb</td>\n      <td>I don't anonymously edit articles at all.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"%%time\nInappContentModel1Preprocessor = Preprocessor( embed_size = 300, \n                                               max_features = 130000, \n                                               max_len = 220, \n                                               model_Type = \"Inappropriate-Content-Detection\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T07:54:26.845576Z","iopub.execute_input":"2022-03-12T07:54:26.845876Z","iopub.status.idle":"2022-03-12T07:54:26.852217Z","shell.execute_reply.started":"2022-03-12T07:54:26.845847Z","shell.execute_reply":"2022-03-12T07:54:26.851368Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"CPU times: user 27 s, sys: 4 s, total: 31 s\nWall time: 35.5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nInappContentModel1Preprocessor.preprocessing( validation_size=0.1,\n                                  embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\",\n                                  embedding_path_glove =\"../input/glove840b300dtxt/glove.840B.300d.txt\" ,\n                                  isEmbeddingIndexFileSaved     = False,\n                                  isEmbeddingMatrixFileSaved    = False,\n                                  wantToSaveEmbeedingIndexFile  = False,\n                                  wantToSaveEmbeedingMatrixFile = False )","metadata":{"execution":{"iopub.status.busy":"2022-03-12T07:54:29.366599Z","iopub.execute_input":"2022-03-12T07:54:29.367112Z","iopub.status.idle":"2022-03-12T08:00:57.363734Z","shell.execute_reply.started":"2022-03-12T07:54:29.367070Z","shell.execute_reply":"2022-03-12T08:00:57.362980Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Building Trainning and Testing is Done.\nSpliting Trainning and Testing is Done.\n(143613,)\nTokenizing is Done.\nEmbeeding Index for Fasttext is Done.\nEmbeeding Index for Glove is Done.\nEmbedding Matrix for FastText is Done., with it's shape as None\nEmbedding Matrix for Glove is Done with shape as None\nCPU times: user 5min 54s, sys: 12.5 s, total: 6min 7s\nWall time: 6min 27s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nInappContentModel1 = ML_Model( InappContentModel1Preprocessor,\n                               file_path = \"1\",\n                               n_multiClassificationClasses = 6 )","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:00:57.370375Z","iopub.execute_input":"2022-03-12T08:00:57.373099Z","iopub.status.idle":"2022-03-12T08:00:57.385542Z","shell.execute_reply.started":"2022-03-12T08:00:57.373040Z","shell.execute_reply":"2022-03-12T08:00:57.384625Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"CPU times: user 78 s, sys: 3 s, total: 81 s\nWall time: 84.2 s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nInappContentModel1.train_Model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 3 )","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:00:57.387114Z","iopub.execute_input":"2022-03-12T08:00:57.387479Z","iopub.status.idle":"2022-03-12T08:11:36.905110Z","shell.execute_reply.started":"2022-03-12T08:00:57.387441Z","shell.execute_reply":"2022-03-12T08:11:36.904340Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"TRAINING STARTED\n","output_type":"stream"},{"name":"stderr","text":"2022-03-12 08:00:57.479132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:57.588956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:57.589693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:57.592349: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-03-12 08:00:57.592688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:57.593716: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:57.594617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:59.481181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:59.481957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:59.482648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-03-12 08:00:59.484041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n2022-03-12 08:01:00.061758: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 156001200 exceeds 10% of free system memory.\n2022-03-12 08:01:00.718253: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 156001200 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"6\n","output_type":"stream"},{"name":"stderr","text":"2022-03-12 08:01:02.388409: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 126379440 exceeds 10% of free system memory.\n2022-03-12 08:01:02.537703: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"},{"name":"stderr","text":"2022-03-12 08:01:13.443639: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1122/1122 [==============================] - 196s 160ms/step - loss: 0.0525 - accuracy: 0.8576 - val_loss: 0.0412 - val_accuracy: 0.9895\n\n ROC-AUC - epoch: 1 - score: 0.989767\n\nEpoch 00001: val_loss improved from inf to 0.04118, saving model to best_model_FrameWork1_Inappropriate-Content-Detection.hdf5\n","output_type":"stream"},{"name":"stderr","text":"2022-03-12 08:04:37.228639: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 156001200 exceeds 10% of free system memory.\n2022-03-12 08:04:37.693977: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 156001200 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/3\n1122/1122 [==============================] - 177s 158ms/step - loss: 0.0414 - accuracy: 0.8990 - val_loss: 0.0400 - val_accuracy: 0.9447\n\n ROC-AUC - epoch: 2 - score: 0.990996\n\nEpoch 00002: val_loss improved from 0.04118 to 0.03997, saving model to best_model_FrameWork1_Inappropriate-Content-Detection.hdf5\nEpoch 3/3\n1122/1122 [==============================] - 178s 159ms/step - loss: 0.0388 - accuracy: 0.8714 - val_loss: 0.0410 - val_accuracy: 0.9286\n\n ROC-AUC - epoch: 3 - score: 0.991161\n\nEpoch 00003: val_loss did not improve from 0.03997\nTRAINING COMPLETED\nCPU times: user 8min 26s, sys: 22.9 s, total: 8min 49s\nWall time: 10min 39s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(InappContentModel1.n_output_nuerons )\nprint(InappContentModel1.modelBase.embedding_matrix_glove.shape[0])\nprint(InappContentModel1.modelBase.max_features)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:11:36.907316Z","iopub.execute_input":"2022-03-12T08:11:36.907745Z","iopub.status.idle":"2022-03-12T08:11:36.913289Z","shell.execute_reply.started":"2022-03-12T08:11:36.907705Z","shell.execute_reply":"2022-03-12T08:11:36.912302Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"6\n130001\n130000\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ny_pred_train = InappContentModel1.get_accuracy_for_training_set()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:11:36.914507Z","iopub.execute_input":"2022-03-12T08:11:36.914889Z","iopub.status.idle":"2022-03-12T08:15:00.976503Z","shell.execute_reply.started":"2022-03-12T08:11:36.914848Z","shell.execute_reply":"2022-03-12T08:15:00.975727Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"4488/4488 [==============================] - 151s 33ms/step\n\n ROC-AUC - ON Validation Dataset - score: 99.167%\nCPU times: user 2min 8s, sys: 7.67 s, total: 2min 15s\nWall time: 3min 24s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ny_pred_valid  = InappContentModel1.get_accuracy_for_validation_set()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:15:00.977849Z","iopub.execute_input":"2022-03-12T08:15:00.978311Z","iopub.status.idle":"2022-03-12T08:15:21.509964Z","shell.execute_reply.started":"2022-03-12T08:15:00.978271Z","shell.execute_reply":"2022-03-12T08:15:21.509107Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"499/499 [==============================] - 17s 33ms/step\n\n ROC-AUC - ON Validation Dataset - score: 99.1%\nCPU times: user 14.3 s, sys: 779 ms, total: 15.1 s\nWall time: 20.5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"InappContentModel1.Plot( \"loss\")\n","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:15:21.511345Z","iopub.execute_input":"2022-03-12T08:15:21.511664Z","iopub.status.idle":"2022-03-12T08:15:21.795851Z","shell.execute_reply.started":"2022-03-12T08:15:21.511625Z","shell.execute_reply":"2022-03-12T08:15:21.795190Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"###### DONE PLOTTING FOR IDEA - 1 ########\n","output_type":"stream"}]},{"cell_type":"code","source":"InappContentModel1.Plot( \"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:15:21.797238Z","iopub.execute_input":"2022-03-12T08:15:21.797719Z","iopub.status.idle":"2022-03-12T08:15:22.045865Z","shell.execute_reply.started":"2022-03-12T08:15:21.797681Z","shell.execute_reply":"2022-03-12T08:15:22.045197Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"name":"stdout","text":"###### DONE PLOTTING FOR IDEA - 1 ########\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\n# CHECKING FOR IDEA 2 BY SWITCHING \nInappContentModel1.change_idea_for_same_object( change_idea_to = \"2\", automatic_train = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2 \ny_pred_valid  = InappContentModel1.get_accuracy_for_validation_set()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA2\nInappContentModel1.Plot( \"accuracy\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2 \nInappContentModel1.Plot( \"loss\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n> **Prediction on Inappropriate Content for testing PreditObject class.**","metadata":{}},{"cell_type":"code","source":"%%time\nInappPrediction = PredictorObject(model_Type = \"Inappropriate-Content-Detection\", file_path = \"1\" ,n_multiClassificationClasses = 6, tweet_column='comment_text'  )","metadata":{"execution":{"iopub.status.busy":"2022-03-12T09:26:13.699843Z","iopub.execute_input":"2022-03-12T09:26:13.700106Z","iopub.status.idle":"2022-03-12T09:26:13.762612Z","shell.execute_reply.started":"2022-03-12T09:26:13.700076Z","shell.execute_reply":"2022-03-12T09:26:13.761827Z"},"trusted":true},"execution_count":7,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/637521017.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, max_len, max_features, model_Type, file_path, n_multiClassificationClasses, tweet_column, *args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#check whether model is already prsent else load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   raise IOError(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m   \u001b[0mmeta_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[0;32m--> 121\u001b[0;31m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: best_model_FrameWork1_Inappropriate-Content-Detection.hdf5/{saved_model.pbtxt|saved_model.pb}"],"ename":"OSError","evalue":"SavedModel file does not exist at: best_model_FrameWork1_Inappropriate-Content-Detection.hdf5/{saved_model.pbtxt|saved_model.pb}","output_type":"error"}]},{"cell_type":"code","source":"# %%time\n# prediction( path_to_Tweet_DataFrame=None, result_filename=None ):","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:57:33.339747Z","iopub.execute_input":"2022-03-12T08:57:33.340199Z","iopub.status.idle":"2022-03-12T08:57:33.344163Z","shell.execute_reply.started":"2022-03-12T08:57:33.340164Z","shell.execute_reply":"2022-03-12T08:57:33.343018Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"test_data_path = '../input/jigsaw-toxic-comment-classification-challenge/test.csv'\nInappPrediction.prediction( None,isText=False, isArray=False, isDataFrame=True, path_to_Tweet_DataFrame=test_data_path )","metadata":{"execution":{"iopub.status.busy":"2022-03-12T08:57:35.398594Z","iopub.execute_input":"2022-03-12T08:57:35.399320Z","iopub.status.idle":"2022-03-12T09:00:21.797584Z","shell.execute_reply.started":"2022-03-12T08:57:35.399271Z","shell.execute_reply":"2022-03-12T09:00:21.795724Z"},"trusted":true},"execution_count":57,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/1564930777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input/jigsaw-toxic-comment-classification-challenge/test.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mInappPrediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0misText\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misArray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misDataFrame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_to_Tweet_DataFrame\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data_path\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/1262661827.py\u001b[0m in \u001b[0;36mprediction\u001b[0;34m(self, tweet_data, isText, isArray, isDataFrame, path_to_Tweet_DataFrame, result_filename)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweet_column\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"],"ename":"IndexError","evalue":"only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **SPAM DETECTION**","metadata":{}},{"cell_type":"code","source":"%%time\nspamDetectionModel1Preprocessor = Preprocessor( embed_size = 300, \n                                               max_features = 130000, \n                                               max_len = 220, \n                                               model_Type = \"Spam-Detection\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%%time\nspamDetectionModel1Preprocessor.preprocessing( validation_size=0.1,\n                                  embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\",\n                                  embedding_path_glove =\"../input/glove840b300dtxt/glove.840B.300d.txt\" ,\n                                  isEmbeddingIndexFileSaved     =False,\n                                  isEmbeddingMatrixFileSaved    = False,\n                                  wantToSaveEmbeedingIndexFile  = False,\n                                  wantToSaveEmbeedingMatrixFile = False )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%%time\nspamDetectionModel1 = ML_Model( spamDetectionModel1Preprocessor,\n                               file_path = \"1\",\n                               n_multiClassificationClasses = 1 )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nspamDetectionModel1.train_Model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 3 )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_pred_valid  = spamDetectionModel1.get_accuracy_for_validation_set()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spamDetectionModel1.Plot( \"loss\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spamDetectionModel1.Plot( \"accuracy\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# CHECKING FOR IDEA 2 BY SWITCHING \nspamDetectionModel1.change_idea_for_same_object( change_idea_to = \"2\", automatic_train = True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%%time\n# Note this prediction is  FOR IDEA 2\ny_pred_train = spamDetectionModel1.get_accuracy_for_training_set()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2 \ny_pred_valid  = spamDetectionModel1.get_accuracy_for_validation_set()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2 \nspamDetectionModel1.Plot( \"loss\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2\nspamDetectionModel1.Plot( \"accuracy\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2\ny_pred_train = InappContentModel1.get_accuracy_for_training_set()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IDEA -1 BI-GRU & LSTM WITH DUAL EMBEDDINGS(FAST TEXT + GLOVE).**","metadata":{}},{"cell_type":"code","source":"#Importing all the libraries \n\nimport time\nstart_time = time.time()\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\n# from keras.engine import InputSpec, Layer\nfrom keras.layers import Layer\nfrom keras.layers import InputSpec\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport_time = round((time.time()-start_time)*1000,3)\n\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nprint(f\"'ALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : {import_time} msec\")\n","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:06:24.287486Z","iopub.execute_input":"2022-02-26T17:06:24.28767Z","iopub.status.idle":"2022-02-26T17:06:24.297811Z","shell.execute_reply.started":"2022-02-26T17:06:24.287646Z","shell.execute_reply":"2022-02-26T17:06:24.297066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Customized Class to handle ROC AUC Evaluation for each epoch and printing epoch number and score for each epoch which is multiple of interval.  \nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:06:24.299055Z","iopub.execute_input":"2022-02-26T17:06:24.299642Z","iopub.status.idle":"2022-02-26T17:06:24.309212Z","shell.execute_reply.started":"2022-02-26T17:06:24.299609Z","shell.execute_reply":"2022-02-26T17:06:24.307646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the training and testing data i.e converting that into dataframes\ntrain = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ntest  = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-26T17:06:24.310745Z","iopub.execute_input":"2022-02-26T17:06:24.311042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Columns of training data\ntrain.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Columns of test data\ntest.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\nembedding_path_glove    = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 130000 #Vocabulary Size \nmax_len = 220  # maximum length of tweet. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\ntrain[\"comment_text\"].fillna(\"no comment\")\ntest[\"comment_text\"].fillna(\"no comment\")\n\n\nvalidation_size = 0.1 \n# splitting train:dev -->  9:1 so train consist of 90 percent and validation set consist of 10 percent of entire training data \n#Note : This validation_size is configurable and can be changed later.\nX_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = validation_size)\n\n\n\n# Lowering all the comments of training, validation and test data let callled it as raw.\nraw_text_train = X_train[\"comment_text\"].str.lower()\nraw_text_valid = X_valid[\"comment_text\"].str.lower()\nraw_text_test = test[\"comment_text\"].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Artcle for better undrstanding of Tokenizer : https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/\n\n# num_words = the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\ntk = Tokenizer(num_words = max_features)\n#Tokeinzing the raw training set\ntk.fit_on_texts(raw_text_train)\n# print(raw_text_train.shape )\nX_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train)\nX_valid[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid)\ntest[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n\nX_train = pad_sequences(X_train.comment_seq, maxlen = max_len)\nX_valid = pad_sequences(X_valid.comment_seq, maxlen = max_len)\ntest = pad_sequences(test.comment_seq, maxlen = max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Embeeding Index which can help further to create embedding matrix for the words in our training dataset vocabulary.\n# This Ebedding index is created from the fastText or Glove.\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n\n#Embedding Index correpsonding to FastText\nembedding_index_fastText = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_fastText))\n\n#Embedding Index correpsonding to Glove\nembedding_index_glove = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_glove))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(embedding_index_fastText))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(embedding_index_glove))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_index_fastText.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_index_glove.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_index_fastText['spam'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_index_glove['spam'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_index_fastText['spam'][:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_index_glove['spam'][:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_index_fastText['spam'][-10+1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_index_glove['spam'][-10+1:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing Our Embeeding matrix from Embedding Index from glove or fastText. \ndamword_index = tk.word_index\nnb_words = min(max_features, len(damword_index))\nembedding_matrix_fastText = np.zeros((nb_words, embed_size))\nembedding_matrix_glove = np.zeros((nb_words, embed_size))\n\nfor word, i in damword_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index_fastText.get(word)\n    if embedding_vector is not None: embedding_matrix_fastText[i] = embedding_vector\n        \nfor word, i in damword_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index_glove.get(word)\n    if embedding_vector is not None: embedding_matrix_glove[i] = embedding_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_fastText[2][:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_glove[2][:10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_matrix_fastText[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(embedding_matrix_glove[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, RMSprop\n# from keras.optimizers import  RMSprop, adam_v2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"best_model_idea1.hdf5\"  #Nmae by whihc Model is to be saved \ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n\n#Allowing early stopping\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n    inp = Input(shape = (max_len,))\n    x_fastText = Embedding(max_features, embed_size, weights = [embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n    x_glove = Embedding(max_features, embed_size, weights = [embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n    \n    #Drop-Out Layer\n    x1_fastText = SpatialDropout1D(dr)(x_fastText)\n    x1_glove = SpatialDropout1D(dr)(x_glove)\n\n    ### FastText\n    #BI-GRU , FastText\n    x_gru_fastText = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    x_conv_gru_fastText = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_gru_fastText)\n    \n    #BI-LSTM , FastText\n    x_lstm_fastText = Bidirectional(LSTM(units, return_sequences = True))(x1_fastText)\n    x_conv_lstm_fastText = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_lstm_fastText)\n    \n    ### Glove\n    #BI-GRU , Glove\n    x_gru_glove = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_conv_gru_glove = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_gru_glove)\n    \n    #BI-LSTM , Glove\n    x_lstm_glove = Bidirectional(LSTM(units, return_sequences = True))(x1_glove)\n    x_conv_lstm_glove = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_lstm_glove)\n    \n    \n    ### FastText\n    #POOLING_CONV ,BI-GRU, FastText\n    avg_pool1_gru_fastText = GlobalAveragePooling1D()(x_conv_gru_fastText)\n    max_pool1_gru_fastText = GlobalMaxPooling1D()(x_conv_gru_fastText)\n    \n    #POOLING_CONV ,BI-LSTM, FastText\n    avg_pool2_lstm_fastText = GlobalAveragePooling1D()(x_conv_lstm_fastText)\n    max_pool2_lstm_fastText = GlobalMaxPooling1D()(x_conv_lstm_fastText)\n    \n    \n    ### Glove\n    #POOLING_CONV ,BI-GRU, Glove\n    avg_pool1_gru_glove = GlobalAveragePooling1D()(x_conv_gru_glove)\n    max_pool1_gru_glove = GlobalMaxPooling1D()(x_conv_gru_glove)\n    \n    #POOLING_CONV ,BI-LSTM, Glove\n    avg_pool2_lstm_glove = GlobalAveragePooling1D()(x_conv_lstm_glove)\n    max_pool2_lstm_glove = GlobalMaxPooling1D()(x_conv_lstm_glove)\n    \n    \n    #Concatenating FastText Branch\n    x_fastText = concatenate([avg_pool1_gru_fastText, max_pool1_gru_fastText, avg_pool2_lstm_fastText, max_pool2_lstm_fastText])\n    \n    #Concatenating Glove Branch\n    x_glove = concatenate([avg_pool1_gru_glove, max_pool1_gru_glove, avg_pool2_lstm_glove, max_pool2_lstm_glove])\n  \n    \n#     x = x_fastText  #Comment this line when below line got  un-commented\n    #Finally Concatenating Both the branches\n    x = concatenate([x_fastText, x_glove])\n    \n    #Passing concatenated output to dense network\n    x = Dense(6, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = x)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n#     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, Y_train, batch_size = 128, epochs = epochs, validation_data = (X_valid, Y_valid), \n                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n    model = load_model(file_path)\n    return model,history\n    \n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trainng The Model\nmodel,history = build_model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 3)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting The Model\n\npred = model.predict(test, batch_size = 1024, verbose = 1)\n\nsubmission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\nsubmission[list_classes] = (pred)\nsubmission.to_csv(\"submission.csv\", index = False)\nprint(\"[{}] Completed!\".format(time.time() - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[132]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC-AUC Evaluation  \n# https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n\n\ny_pred_validation = model.predict(X_valid, verbose=1)\nscore_validation = roc_auc_score(Y_valid, y_pred_validation)\nprint(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = model.predict(X_train, verbose=1)\nscore_train = roc_auc_score(Y_train, y_pred_train)\nprint(f\"\\n ROC-AUC - Training Dataset - score: {round(score_train,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model.predict(X_valid,verbose=1)\n# pred_prob = model.predict_proba(X_valid)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(pred[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef Plot(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_' + string])\n    plt.xlabel(\"EPOCHS\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_' + string ])\n    plt.savefig(string + '_IDEA1.png')\n    plt.show()\n    \n    \nPlot(history, \"accuracy\")\nPlot(history, \"loss\")\n\n\nprint(\"###### DONE PLOTTING FOR IDEA 1 ########\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **ROC-AUC PLOTTING**","metadata":{}},{"cell_type":"code","source":"predict_probability = np.zeros(shape=pred.shape,dtype='int64')\nno_classes = len(pred[0])\nno_of_examples = len(pred)\nfor i in range(no_of_examples):\n    maxi_index = 0\n    maximum_element = pred[i][0]\n    for j in range(1,no_classes):\n        if maximum_element<pred[i][j]:\n            maximum_element = pred[i][j]\n            maxi_index = j\n    predict_probability[i][maxi_index] = 1\n      \n            \n        \n    \n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_probability","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_probability.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_valid.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_valid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roc_pred = np.zeros(no_of_examples,dtype='int64')\n# for i in range(no_of_examples):\n#     for j in range(no_classes):\n#         if pred[i][j]==1:\n#             roc_pred[i]=j\n#             break\n            \n            \ny_validation = np.zeros(no_of_examples,dtype='int64')\nfor i in range(no_of_examples):\n    for j in range(no_classes):\n        if Y_valid[i][j]==1:\n            y_validation[i]=j\n            break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# roc curve for classes\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\nfpr = {}\ntpr = {}\nthresh ={}\n\nn_class = no_classes\n\nfor i in range(n_class):    \n    fpr[i], tpr[i], thresh[i] = roc_curve(y_validation, predict_probability[:,i], pos_label=i)\n    \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plotting    \nplt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\nplt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\nplt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\nplt.plot(fpr[3], tpr[3], linestyle='--',color='red', label='Class 3 vs Rest')\nplt.plot(fpr[4], tpr[4], linestyle='--',color='black', label='Class 4 vs Rest')\nplt.plot(fpr[5], tpr[5], linestyle='--',color='brown', label='Class 5 vs Rest')\nplt.title('Multiclass ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive rate')\nplt.legend(loc='best')\nplt.savefig('Multiclass ROC',dpi=300); ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #  multi-class classification\n# from sklearn.multiclass import OneVsRestClassifier\n# from sklearn.linear_model import LogisticRegression\n# from sklearn.model_selection import train_test_split\n# from sklearn.metrics import roc_curve\n# from sklearn.metrics import roc_auc_score\n# from sklearn.datasets import make_classification\n# from sklearn.model_selection import train_test_split\n# import matplotlib.pyplot as plt\n\n# # generate 2 class dataset\n# X, y = make_classification(n_samples=1000, n_classes=3, n_features=20, n_informative=3, random_state=42)\n\n# # split into train/test sets\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n\n# # fit model\n# clf = OneVsRestClassifier(LogisticRegression())\n# clf.fit(X_train, y_train)\n# pred = clf.predict(X_test)\n# pred_prob = clf.predict_proba(X_test)\n\n# # roc curve for classes\n# fpr = {}\n# tpr = {}\n# thresh ={}\n\n# n_class = 3\n\n\n\n# for i in range(n_class):    \n#     fpr[i], tpr[i], thresh[i] = roc_curve(y_test, pred_prob[:,i], pos_label=i)\n    \n# # plotting    \n# plt.plot(fpr[0], tpr[0], linestyle='--',color='orange', label='Class 0 vs Rest')\n# plt.plot(fpr[1], tpr[1], linestyle='--',color='green', label='Class 1 vs Rest')\n# plt.plot(fpr[2], tpr[2], linestyle='--',color='blue', label='Class 2 vs Rest')\n# plt.title('Multiclass ROC curve')\n# plt.xlabel('False Positive Rate')\n# plt.ylabel('True Positive rate')\n# plt.legend(loc='best')\n# plt.savefig('Multiclass ROC',dpi=300);    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_prob","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_fastText.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_glove.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  **DUAL EMBEDDINGS**","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# import os\n# from keras.models import Model\n# from keras.layers import Input, Dense, Embedding, SpatialDropout1D, add, concatenate\n# from keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D, CuDNNGRU, Conv1D\n# from keras.preprocessing import text, sequence\n# from keras.callbacks import LearningRateScheduler\n# from sklearn.metrics import roc_auc_score\n# from sklearn.model_selection import train_test_split\n# import tensorflow as tf\n# print(tf.__version__)\n# tf.test.is_gpu_available(\n#     cuda_only=False,\n#     min_cuda_compute_capability=None\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EMBEDDING_FILES = [\n#         '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec',\n#     '../input/glove840b300dtxt/glove.840B.300d.txt'\n# ]\n\n\n# BATCH_SIZE = 512\n# LSTM_UNITS = 128\n# DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n# EPOCHS = 4\n# MAX_LEN = 220\n\n\n# TEXT_COLUMN = 'comment_text'\n# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n# CHARS_TO_REMOVE = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\'\\'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/train.csv')\n# test_df = pd.read_csv('../input/jigsaw-toxic-comment-classification-challenge/test.csv')\n# submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n\n# y = train_df[list_classes].values\n# x_train = train_df[TEXT_COLUMN].astype(str)\n# y_train = y\n# x_test = test_df[TEXT_COLUMN].astype(str)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def get_coefs(word, *arr):\n#     return word, np.asarray(arr, dtype='float32')\n\n\n# def load_embeddings(path):\n#     with open(path) as f:\n#         return dict(get_coefs(*line.strip().split(' ')) for line in f)\n\n\n# def build_matrix(word_index, path):\n#     embedding_index = load_embeddings(path)\n#     embedding_matrix = np.zeros((len(word_index) + 1, 300))\n#     for word, i in word_index.items():\n#         try:\n#             embedding_matrix[i] = embedding_index[word]\n#         except KeyError:\n#             pass\n#     return embedding_matrix\n\n# def build_model(embedding_matrix):\n#     words = Input(shape=(None,))\n#     x = Embedding(*embedding_matrix.shape, weights=[embedding_matrix], trainable=False)(words)\n#     #x = SpatialDropout1D(0.2)(x)\n\n#     x1 = SpatialDropout1D(0.2)(x)\n\n#     x = Bidirectional(CuDNNGRU(LSTM_UNITS, return_sequences = True))(x1)\n#     x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n    \n#     y = Bidirectional(CuDNNLSTM(LSTM_UNITS, return_sequences = True))(x1)\n#     y = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(y)\n\n\n#     avg_pool1 = GlobalAveragePooling1D()(x)\n#     max_pool1 = GlobalMaxPooling1D()(x)\n   \n#     avg_pool2 = GlobalAveragePooling1D()(y)\n#     max_pool2 = GlobalMaxPooling1D()(y)\n   \n\n#     x = concatenate([avg_pool1, max_pool1, avg_pool2, max_pool2])\n\n\n#     x = Dense(6, activation = \"sigmoid\")(x)\n\n#     model = Model(inputs = words, outputs = x)\n\n#     model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n\n#     return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# tokenizer = text.Tokenizer(filters=CHARS_TO_REMOVE)\n# tokenizer.fit_on_texts(list(x_train) + list(x_test))\n\n# x_train = tokenizer.texts_to_sequences(x_train)\n# x_test = tokenizer.texts_to_sequences(x_test)\n# x_train = sequence.pad_sequences(x_train, maxlen=MAX_LEN)\n# x_test = sequence.pad_sequences(x_test, maxlen=MAX_LEN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%time\n# embedding_matrix = np.concatenate(\n#     [build_matrix(tokenizer.word_index, f) for f in EMBEDDING_FILES], axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IDEA -2 BI-GRU & LSTM WITH DUAL EMBEDDINGS(FAST TEXT + GLOVE).**","metadata":{}},{"cell_type":"code","source":"#Importing all the libraries \n\nprint(\"WORKING ON IDEA 2....\")\n\nimport time\nstart_time = time.time()\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\n# from keras.engine import InputSpec, Layer\nfrom keras.layers import Layer\nfrom keras.layers import InputSpec\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport_time = round((time.time()-start_time)*1000,3)\n\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nprint(f\"'ALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : {import_time} msec\")\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Customized Class to handle ROC AUC Evaluation for each epoch and printing epoch number and score for each epoch which is multiple of interval.  \nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the training and testing data i.e converting that into dataframes\ntrain = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\ntest  = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Columns of training data\ntrain.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Columns of test data\ntest.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\nembedding_path_glove    = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 130000 #Vocabulary Size \nmax_len = 220  # maximum length of tweet. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\ntrain[\"comment_text\"].fillna(\"no comment\")\ntest[\"comment_text\"].fillna(\"no comment\")\n\nvalidation_size = 0.1 \n# splitting train:dev -->  9:1 so train consist of 90 percent and validation set consist of 10 percent of entire training data \n#Note : This validation_size is configurable and can be changed later.\nX_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = validation_size)\n\n\n\n# Lowering all the comments of training, validation and test data let callled it as raw.\nraw_text_train = X_train[\"comment_text\"].str.lower()\nraw_text_valid = X_valid[\"comment_text\"].str.lower()\nraw_text_test = test[\"comment_text\"].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Article for better undrstanding of Tokenizer : https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/\n\n# num_words = the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\ntk = Tokenizer(num_words = max_features)\n#Tokeinzing the raw training set\ntk.fit_on_texts(raw_text_train)\n# print(raw_text_train.shape )\nX_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train)\nX_valid[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid)\ntest[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n\nX_train = pad_sequences(X_train.comment_seq, maxlen = max_len)\nX_valid = pad_sequences(X_valid.comment_seq, maxlen = max_len)\ntest = pad_sequences(test.comment_seq, maxlen = max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Embeeding Index which can help further to create embedding matrix for the words in our training dataset vocabulary.\n# This Ebedding index is created from the fastText or Glove.\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n\n#Embedding Index correpsonding to FastText\nembedding_index_fastText = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_fastText))\n\n#Embedding Index correpsonding to Glove\nembedding_index_glove = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_glove))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing Our Embeeding matrix from Embedding Index from glove or fastText. \ndamword_index = tk.word_index\nnb_words = min(max_features, len(damword_index))\nembedding_matrix_fastText = np.zeros((nb_words, embed_size))\nembedding_matrix_glove = np.zeros((nb_words, embed_size))\n\nfor word, i in damword_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index_fastText.get(word)\n    if embedding_vector is not None: embedding_matrix_fastText[i] = embedding_vector\n        \nfor word, i in damword_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index_glove.get(word)\n    if embedding_vector is not None: embedding_matrix_glove[i] = embedding_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, RMSprop\n# from keras.optimizers import  RMSprop, adam_v2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"best_model_idea2.hdf5\"  #Nmae by whihc Model is to be saved \ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n\n#Allowing early stopping\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n    inp = Input(shape = (max_len,))\n    x_fastText = Embedding(max_features, embed_size, weights = [embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n    x_glove = Embedding(max_features, embed_size, weights = [embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n    \n    #Drop-Out Layer\n    x1_fastText = SpatialDropout1D(dr)(x_fastText)\n    x1_glove = SpatialDropout1D(dr)(x_glove)\n    \n    \n    #BI-LSTM BRANCH\n    x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    \n    \n    #BI-GRU BRNACH\n    x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    \n    \n    #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n    \n    #Bi-listm\n    x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n    x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n    x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n    #concatenating\n    x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n    \n    \n    \n    x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n    x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n    x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n    #concatenating\n    x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n    \n    \n    #Bi-gru\n    x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n    x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n    x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n    #concatenating\n    x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n    \n    \n    \n    x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n    x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n    x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n    #concatenating\n    x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n    \n    \n    \n    #Con-Catenating Bi-Lstm branch\n    x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n    \n    #Con-Catenating Bi-Gru branch\n    x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n    \n    #ConCatenating Bi-LSTM and Bi-GRU Branch\n    x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n    \n    \n    #Passing concatenated output to dense network\n    x = Dense(6, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    model = Model(inputs = inp, outputs = x)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n#     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, Y_train, batch_size = 128, epochs = epochs, validation_data = (X_valid, Y_valid), \n                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n    model = load_model(file_path)\n    return model,history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trainng The Model\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n#Training The Model\nmodel,history = build_model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Predicting The Model\n\npred = model.predict(test, batch_size = 1024, verbose = 1)\n\nsubmission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\nsubmission[list_classes] = (pred)\nsubmission.to_csv(\"submissionIdea2.csv\", index = False)\nprint(\"[{}] Completed!\".format(time.time() - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC-AUC Evaluation  \n# https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n\n\ny_pred_validation = model.predict(X_valid, verbose=1)\nscore_validation = roc_auc_score(Y_valid, y_pred_validation)\nprint(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = model.predict(X_train, verbose=1)\nscore_train = roc_auc_score(Y_train, y_pred_train)\nprint(f\"\\n ROC-AUC - Training Dataset - score: {round(score_train,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef Plot(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_' + string])\n    plt.xlabel(\"EPOCHS\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_' + string ])\n    plt.savefig(string + '_IDEA2.png')\n    plt.show()\n    \n    \nPlot(history, \"accuracy\")\nPlot(history, \"loss\")\n\n\nprint(\"###### DONE PLOTTING FOR IDEA 2 ########\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **IDEA 1 FOR SPAM DETECTION**","metadata":{}},{"cell_type":"code","source":"#Importing all the libraries \n\nprint(\"WORKING ON IDEA 2....\")\n\nimport time\nstart_time = time.time()\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\n# from keras.engine import InputSpec, Layer\nfrom keras.layers import Layer\nfrom keras.layers import InputSpec\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport_time = round((time.time()-start_time)*1000,3)\n\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nprint(f\"'ALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : {import_time} msec\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Customized Class to handle ROC AUC Evaluation for each epoch and printing epoch number and score for each epoch which is multiple of interval.  \nclass RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the training and testing data i.e converting that into dataframes\ntrain_df1 = pd.read_csv(\"../input/spam-or-not-spam-dataset/spam_or_not_spam.csv\")\ntrain_df2  = pd.read_csv(\"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.rename(columns={train_df1.columns[0] : \"Message\", train_df1.columns[1] : \"Category\" },inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2[train_df2.columns[0]].replace({\"ham\": 0, \"spam\": 1}, inplace=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2 = train_df2[[train_df2.columns[1],train_df2.columns[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([train_df1, train_df2], ignore_index=True, sort=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[\"Category\"].values\n# y = np.asarray(y).astype(np.float32)\ntrain[\"Message\"].fillna(\"no comment\")\n# train_df2[\"Message\"].fillna(\"no comment\")\n\nvalidation_size = 0.1 \n# splitting train:dev -->  9:1 so train consist of 90 percent and validation set consist of 10 percent of entire training data \n#Note : This validation_size is configurable and can be changed later.\nX_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = validation_size)\n\n\n\n# Lowering all the comments of training, validation and test data let callled it as raw.\nraw_text_train = X_train[\"Message\"].str.lower()\nraw_text_valid = X_valid[\"Message\"].str.lower()\n# raw_test_valid = X_test[\"Message\"].str.lower()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_text_train.isnull().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_text_train[raw_text_train.isnull()].index.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\nembedding_path_glove    = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 130000 #Vocabulary Size \nmax_len = 220  # maximum length of tweet. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Article for better undrstanding of Tokenizer : https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/\n\n# num_words = the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\ntk = Tokenizer(num_words = max_features)\n\n#Tokeinzing the raw training set\ntk.fit_on_texts(raw_text_train)\nprint(raw_text_train.shape )\n\n\n\nX_train[\"Message\"] = tk.texts_to_sequences(raw_text_train)\nX_valid[\"Message\"] = tk.texts_to_sequences(raw_text_valid)\n# test[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n\nX_train = pad_sequences(X_train.Message, maxlen = max_len)\nX_valid = pad_sequences(X_valid.Message, maxlen = max_len)\n# test = pad_sequences(test.comment_seq, maxlen = max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating Embeeding Index which can help further to create embedding matrix for the words in our training dataset vocabulary.\n# This Ebedding index is created from the fastText or Glove.\ndef get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n\n#Embedding Index correpsonding to FastText\nembedding_index_fastText = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_fastText))\n\n#Embedding Index correpsonding to Glove\nembedding_index_glove = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_glove))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(tk.word_index.keys())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preparing Our Embeeding matrix from Embedding Index from glove or fastText. \ndamword_index = tk.word_index\nnb_words = min(max_features, 1+len(damword_index))\nembedding_matrix_fastText = np.zeros((nb_words, embed_size))\nembedding_matrix_glove = np.zeros((nb_words, embed_size))\n\nfor word, i in damword_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index_fastText.get(word)\n    if embedding_vector is not None: embedding_matrix_fastText[i] = embedding_vector\n        \nfor word, i in damword_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index_glove.get(word)\n    if embedding_vector is not None: embedding_matrix_glove[i] = embedding_vector","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam, RMSprop\n# from keras.optimizers import  RMSprop, adam_v2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"best_model_idea1_SPAM-DETECTION.hdf5\"  #Nmae by whihc Model is to be saved \ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n\n#Allowing early stopping\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n    inp = Input(shape = (max_len,))\n    x_fastText = Embedding(min(max_features,1+len(tk.word_index)), embed_size, weights = [embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n    x_glove = Embedding(min(max_features,1+len(tk.word_index)), embed_size, weights = [embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n    \n    #Drop-Out Layer\n    x1_fastText = SpatialDropout1D(dr)(x_fastText)\n    x1_glove = SpatialDropout1D(dr)(x_glove)\n    \n    \n    #BI-LSTM BRANCH\n    x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    \n    \n    #BI-GRU BRNACH\n    x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    \n    \n    #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n    \n    #Bi-listm\n    x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n    x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n    x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n    #concatenating\n    x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n    \n    \n    \n    x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n    x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n    x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n    #concatenating\n    x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n    \n    \n    #Bi-gru\n    x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n    x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n    x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n    #concatenating\n    x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n    \n    \n    \n    x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n    x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n    x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n    #concatenating\n    x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n    \n    \n    \n    #Con-Catenating Bi-Lstm branch\n    x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n    \n    #Con-Catenating Bi-Gru branch\n    x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n    \n    #ConCatenating Bi-LSTM and Bi-GRU Branch\n    x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n    \n    \n    #Passing concatenated output to dense network\n#     xxxx = Dense(8, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n#     xxx = Dense(4, activation = \"sigmoid\")(xxxx)\n#     xx = Dense(2, activation = \"sigmoid\")(xx)\n#     x = Dense(1, activation = \"sigmoid\")(xx)\n\n    \n    x = Dense(1, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    model = Model(inputs = inp, outputs = x)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n#     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, Y_train, batch_size = 128, epochs = epochs, validation_data = (X_valid, Y_valid), \n                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n    model = load_model(file_path)\n    return model,history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trainng The Model\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n#Training The Model\nmodel,history = build_model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 30)\n\n#best is 7","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Predicting The Model\n\n# pred = model.predict(test, batch_size = 1024, verbose = 1)\n\n# submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n# submission[list_classes] = (pred)\n# submission.to_csv(\"submissionIdea2.csv\", index = False)\n# print(\"[{}] Completed!\".format(time.time() - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC-AUC Evaluation  \n# https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n\n\ny_pred_validation = model.predict(X_valid, verbose=1)\nscore_validation = roc_auc_score(Y_valid, y_pred_validation)\nprint(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = model.predict(X_train, verbose=1)\nscore_train = roc_auc_score(Y_train, y_pred_train)\nprint(f\"\\n ROC-AUC - Training Dataset - score: {round(score_train,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\ndef Plot(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_' + string])\n    plt.xlabel(\"EPOCHS\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_' + string ])\n    plt.savefig(string + '_IDEA1.png')\n    plt.show()\n    \n    \nPlot(history, \"accuracy\")\nPlot(history, \"loss\")\n\n\nprint(\"###### DONE PLOTTING FOR IDEA 1 ########\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ****IDEA 2 FOR SPAM DETECTION****","metadata":{}},{"cell_type":"markdown","source":"**Importing all the libraries**","metadata":{}},{"cell_type":"code","source":"#Importing all the libraries \n\nprint(\"WORKING ON IDEA 2....\")\n\nimport time\nstart_time = time.time()\n\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd, matplotlib.pyplot as plt \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.layers import Layer\nfrom keras.layers import InputSpec\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n# from keras.optimizers import  RMSprop, adam_v2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport_time = round((time.time()-start_time)*1000,3)\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nprint(f\"'ALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : {import_time} msec\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Epoch Class Handler**","metadata":{}},{"cell_type":"code","source":"class RocAucEvaluation(Callback):\n    '''\n     Customized Class to handle ROC AUC Evaluation for each epoch and printing epoch number and score for each epoch which is multiple of interval.  \n    '''\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Reading the dataset**","metadata":{}},{"cell_type":"code","source":"def read_dataset(filepath):\n    '''\n    Reading the training and testing data i.e converting that into dataframes\n\n    input : file path \n    ----------------\n    output : dataframe \n    '''\n    df = pd.read_csv(filepath)\n    return df ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1 = read_dataset(\"../input/spam-or-not-spam-dataset/spam_or_not_spam.csv\")\ntrain_df2  = read_dataset(\"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df1 = pd.read_csv(\"../input/spam-or-not-spam-dataset/spam_or_not_spam.csv\")\n# train_df2  = pd.read_csv(\"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.rename(columns={train_df1.columns[0] : \"Message\", train_df1.columns[1] : \"Category\" },inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.columns[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2[train_df2.columns[0]].replace({\"ham\": 0, \"spam\": 1}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2 = train_df2[[train_df2.columns[1],train_df2.columns[0]]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Constant and Embeeding PATH**","metadata":{}},{"cell_type":"code","source":"embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\"\nembedding_path_glove    = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 130000 #Vocabulary Size \nmax_len = 220  # maximum length of tweet. ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.concat([train_df1, train_df2], ignore_index=True, sort=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df1.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df2.tail(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.dropna()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_builder(train,validation_size=0.1):\n    '''\n    Input : training dataset Dataframe -> train\n    ------------\n    Output : Training and dev dataframe with X and Y values along with raw train and dev set with all comments in lower.\n    '''\n    # list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n    y = train[\"Category\"].values\n    # y = np.asarray(y).astype(np.float32)\n    train[\"Message\"].fillna(\"no comment\")\n    # train_df2[\"Message\"].fillna(\"no comment\")\n\n    validation_size = validation_size   #by default it is 0.1\n    # splitting train:dev -->  9:1 so train consist of 90 percent and validation set consist of 10 percent of entire training data \n    #Note : This validation_size is configurable and can be changed later.\n    X_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = validation_size)\n\n    # Lowering all the comments of training, validation and test data let callled it as raw.\n    raw_text_train = X_train[\"Message\"].str.lower()\n    raw_text_valid = X_valid[\"Message\"].str.lower()\n    # raw_test_valid = X_test[\"Message\"].str.lower()\n    \n    \n#     print(y.dtype)\n\n    return (X_train,X_valid, Y_train, Y_valid, raw_text_train, raw_text_valid, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, Y_train, Y_valid, raw_text_train, raw_text_valid, y = train_test_builder(train, validation_size=0.1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_text_train.isnull().sum().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_text_train[raw_text_train.isnull()].index.tolist()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tokinizing**","metadata":{}},{"cell_type":"code","source":"def tokenizer(raw_text_train, raw_text_valid, X_train, X_valid, max_features, max_len):\n    \n    '''\n    Input : raw train and dev set along with in-rawed train and dev set.\n    --------------------------------------------------------------------------------\n    Output: tokenizer object along with padded and sequenced training and validation dataset\n    '''\n    \n    # Article for better undrstanding of Tokenizer : https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/\n\n    # num_words = the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n    tk = Tokenizer(num_words = max_features)\n\n    #Tokeinzing the raw training set\n    tk.fit_on_texts(raw_text_train)\n    print(raw_text_train.shape )\n    \n    X_train[\"Message\"] = tk.texts_to_sequences(raw_text_train)\n    X_valid[\"Message\"] = tk.texts_to_sequences(raw_text_valid)\n    # test[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)\n\n    X_train = pad_sequences(X_train.Message, maxlen = max_len)\n    X_valid = pad_sequences(X_valid.Message, maxlen = max_len)\n    # test = pad_sequences(test.comment_seq, maxlen = max_len)\n    \n    return (tk, X_train, X_valid)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tk, X_train, X_valid = tokenizer(raw_text_train, raw_text_valid, X_train, X_valid, max_features, max_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Embedding Index Builer**","metadata":{}},{"cell_type":"code","source":"\ndef get_coefs(word,*arr): \n    '''\n    Creating Embeeding Index which can help further to create embedding matrix for the words in our training dataset vocabulary.\n    This Ebedding index is created from the fastText or Glove.\n    '''\n    return word, np.asarray(arr, dtype='float32')\n\n\n\n\n#Embedding Index correpsonding to FastText\nembedding_index_fastText = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_fastText))\n\n#Embedding Index correpsonding to Glove\nembedding_index_glove = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path_glove))\n\nprint(len(tk.word_index.keys()))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Embdding Matrix Builder**","metadata":{}},{"cell_type":"code","source":"def embeeding_Matrix_Builder(tk, max_features, embed_size, embedding_index_fastText, embedding_matrix_glove):\n    '''\n    Input : tokenizer object , with maximum features and embedding size along with fastText and Glove Embedding Index for building Embeeding Matrix\n    ----------------------------------------------------------------------------------------------------------------------------------------------\n    Output: embedding matix corresponding to FastText and Glove\n    '''\n    # Preparing Our Embeeding matrix from Embedding Index from glove or fastText. \n    damword_index = tk.word_index\n    nb_words = min(max_features, len(damword_index))\n    embedding_matrix_fastText = np.zeros((nb_words+1, embed_size))\n    embedding_matrix_glove = np.zeros((nb_words+1, embed_size))\n\n    for word, i in damword_index.items():\n        if i >= max_features: continue\n        embedding_vector = embedding_index_fastText.get(word)\n        if embedding_vector is not None: embedding_matrix_fastText[i] = embedding_vector\n\n    for word, i in damword_index.items():\n        if i >= max_features: continue\n        embedding_vector = embedding_index_glove.get(word)\n        if embedding_vector is not None: embedding_matrix_glove[i] = embedding_vector\n            \n    return embedding_matrix_fastText, embedding_matrix_glove \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_matrix_fastText, embedding_matrix_glove = embeeding_Matrix_Builder(tk, max_features, embed_size, embedding_index_fastText, embedding_matrix_glove)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path = \"best_model_idea2_spamDETECTION.hdf5\"  #Nmae by whihc Model is to be saved \ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n\n#Allowing early stopping\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n    inp = Input(shape = (max_len,))\n    x_fastText = Embedding(min(max_features,1+len(tk.word_index)), embed_size, weights = [embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n    x_glove = Embedding(min(max_features,1+len(tk.word_index)), embed_size, weights = [embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n    \n    #Drop-Out Layer\n    x1_fastText = SpatialDropout1D(dr)(x_fastText)\n    x1_glove = SpatialDropout1D(dr)(x_glove)\n    \n    \n    #BI-LSTM BRANCH\n    x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    \n    \n    #BI-GRU BRNACH\n    x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n    x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n    \n    \n    #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n    \n    #Bi-listm\n    x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n    x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n    x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n    #concatenating\n    x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n    \n    \n    \n    x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n    x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n    x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n    #concatenating\n    x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n    \n    \n    #Bi-gru\n    x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n    x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n    x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n    #concatenating\n    x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n    \n    \n    \n    x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n    x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n    x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n    #concatenating\n    x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n    \n    \n    \n    #Con-Catenating Bi-Lstm branch\n    x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n    \n    #Con-Catenating Bi-Gru branch\n    x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n    \n    #ConCatenating Bi-LSTM and Bi-GRU Branch\n    x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n    \n    \n    #Passing concatenated output to dense network\n#     xxxx = Dense(8, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n#     xxx = Dense(4, activation = \"sigmoid\")(xxxx)\n#     xx = Dense(2, activation = \"sigmoid\")(xxx)\n#     x = Dense(1, activation = \"sigmoid\")(xx)\n\n    x = Dense(1, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    model = Model(inputs = inp, outputs = x)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n#     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, Y_train, batch_size = 128, epochs = epochs, validation_data = (X_valid, Y_valid), \n                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n    model = load_model(file_path)\n    return model,history","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trainng The Model\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n#Training The Model\nmodel,history = build_model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 30)\n#best is 3 to 5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Predicting The Model\n# pred = model.predict(t, batch_size = 1024, verbose = 1)\n\n# submission = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv\")\n# submission[list_classes] = (pred)\n# submission.to_csv(\"submissionIdea2.csv\", index = False)\n# print(\"[{}] Completed!\".format(time.time() - start_time))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction(dataset, y_actual):\n    y_pred_validation = model.predict(dataset, verbose=1)\n    score_validation = roc_auc_score(y_actual, y_pred_validation)\n    print(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")\n    return y_pred_validation\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_validation = prediction(X_valid, Y_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_train = prediction(X_train, Y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ROC-AUC Evaluation  \n# https://www.analyticsvidhya.com/blog/2020/06/auc-roc-curve-machine-learning/\n\n# y_pred_validation = model.predict(X_valid, verbose=1)\n# score_validation = roc_auc_score(Y_valid, y_pred_validation)\n# print(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred_train = model.predict(X_train, verbose=1)\n# score_train = roc_auc_score(Y_train, y_pred_train)\n# print(f\"\\n ROC-AUC - Training Dataset - score: {round(score_train,5)*100}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Plot(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history['val_' + string])\n    plt.xlabel(\"EPOCHS\")\n    plt.ylabel(string)\n    plt.legend([string, 'val_' + string ])\n    plt.savefig(string + '_IDEA2.png')\n    plt.show()\n    \n    \nPlot(history, \"accuracy\")\nPlot(history, \"loss\")\nprint(\"###### DONE PLOTTING FOR IDEA 2 ########\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **BUILDING MODEL IN OOPS WAY FOR BOTH SPAM/INAPP CONTENT DETECTION**\nThus this helps in providing abstraction and easy way to deploy model as well as will also help in providing an machine learning API for our proposed work. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing all the libraries \n\nprint(\"WORKING ON ML Models in object oriented way....\")\n\nimport time\nstart_time = time.time()\n# from numpy import asarray\n# from numpy import loadtxt\n# from numpy import savetxt\nimport pickle\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd, matplotlib.pyplot as plt \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.layers import Layer\nfrom keras.layers import InputSpec\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback\nfrom tensorflow.keras.optimizers import Adam, RMSprop\n# from keras.optimizers import  RMSprop, adam_v2\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport_time = round((time.time()-start_time)*1000,3)\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\n\n\nprint(f\"'\\n\\nALL LIBRARIES IMPORTED SUCCESSFULLY!!' in TIME : {import_time} msec\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:13:14.31872Z","iopub.execute_input":"2022-02-27T16:13:14.319038Z","iopub.status.idle":"2022-02-27T16:13:19.578598Z","shell.execute_reply.started":"2022-02-27T16:13:14.319002Z","shell.execute_reply":"2022-02-27T16:13:19.577802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RocAucEvaluation(Callback):\n    '''\n     Customized Class to handle ROC AUC Evaluation for each epoch and printing epoch number and score for each epoch which is multiple of interval.  \n    '''\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))\n\n#################################################################################################################################################\n\nclass Modelbase :\n    def __init__(self, embed_size = 300, max_features = 130000, max_len = 220, model_Type = \"Spam-Detection\", *args, **kwargs,):\n        self.model_Type = model_Type\n        self.embed_size = embed_size\n        self.max_features = max_features #Vocabulary Size \n        self.max_len = max_len  # maximum length of tweet. \n        self.X_train = None\n        self.Y_train = None\n        self.X_valid = None\n        self.Y_valid = None\n        self.train = None\n        self.y = None\n        self.raw_text_train = None \n        self.raw_text_valid= None\n        if self.model_Type == \"Spam-Detection\":\n            self.list_classes = [\"ham\", \"spam\"]\n            self.tweet_column = \"Message\"\n            self.train_df1 = None\n            self.train_df2 = None            \n        else:\n            self.list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n            self.tweet_column = \"comment_text\"\n            self.test = None\n            self.raw_test_valid= None        \n            self.X_test =  None\n            \n        \n    def read_dataset(self,filepath):\n        '''\n        Reading the training and testing data i.e converting that into dataframes\n        input : file path \n        ----------------\n        output : dataframe \n        '''\n        df = pd.read_csv(filepath)\n        return df \n    \n    def build_train_test_dev_set(self, \n                                 trainDF1 = \"../input/spam-or-not-spam-dataset/spam_or_not_spam.csv\" , \n                                 trainDF2 = \"../input/spam-text-message-classification/SPAM text message 20170820 - Data.csv\" , \n                                 trainDF  = \"../input/jigsaw-toxic-comment-classification-challenge/train.csv\" , \n                                 testDF   = \"../input/jigsaw-toxic-comment-classification-challenge/test.csv\"  ):\n        \n        if self.model_Type == \"Spam-Detection\"  :\n            self.train_df1 = self.read_dataset(trainDF1)\n            self.train_df2 = self.read_dataset(trainDF2)\n            self.spam_Dataset_Aggregator()\n            self.train = self.train.dropna()\n            return \n        else:    \n            self.train  = self.read_dataset(trainDF)\n            self.test  = self.read_dataset(testDF)\n#             self.train = self.train.dropna()\n            return\n        \n    def spam_Dataset_Aggregator(self):\n        self.train_df1.rename(columns={self.train_df1.columns[0] : \"Message\", self.train_df1.columns[1] : \"Category\" },inplace=True)\n        self.train_df2[self.train_df2.columns[0]].replace({\"ham\": 0, \"spam\": 1}, inplace=True)\n        self.train_df2 = self.train_df2[ [ self.train_df2.columns[1], self.train_df2.columns[0] ] ]\n        self.train = pd.concat([self.train_df1, self.train_df2], ignore_index=True, sort=False)\n        return  \n        \n    def __repr__(self):\n        if self.model_Type == \"Spam-Detection\":\n            return f\"Model for Spam Detection (Ham/Spam detection) \\n Model Type :  {self.model_Type}\"\n        return f\"Model for Inappropraue Content Detection (Ham/Spam detection) \\n Model Type :  {self.model_Type}\" #Inappropriate-Content-Detection\n\n    \n    \n#######################################################################################################################################################\n\n\n\nclass Preprocessor(Modelbase):\n    \n    def __init__(self,embed_size = 300, \n                 max_features = 130000, \n                 max_len = 220, \n                 model_Type = \"Spam-Detection\", \n                 *args, **kwargs):\n#         super(Model, self).__init__()\n        super().__init__(embed_size , max_features, max_len, model_Type)\n        # num_words = the maximum number of words to keep, based on word frequency. Only the most common num_words-1 words will be kept.\n        self.tk = Tokenizer(num_words = max_features)\n        self.embedding_matrix_fastText = None\n        self.embedding_matrix_glove = None\n        self.embedding_index_fastText = None\n        self.embedding_index_glove = None\n        self.embedding_matrix_fastText_shape = None\n        self.embedding_matrix_glove_shape = None\n#         self.embedding_index_fastText_shape = None\n#         self.embedding_index_glove_shape = None\n        \n    def train_test_splitter(self,validation_size=0.1):\n        '''\n        Input : training dataset Dataframe -> train\n        ------------\n        Output : Training and dev dataframe with X and Y values along with raw train and dev set with all comments in lower.\n        '''\n        if self.model_Type != \"Spam-Detection\" :\n            # y = np.asarray(y).astype(np.float32)\n            self.y = self.train[self.list_classes].values\n            self.train[self.tweet_column].fillna(\"no comment\")\n            self.test[self.tweet_column].fillna(\"no comment\") \n#             self.train = self.train.dropna()  #**********************************************************\n        else:\n            self.y = self.train[\"Category\"].values\n            # y = np.asarray(y).astype(np.float32)\n            self.train[self.tweet_column].fillna(\"no comment\")\n        # train_df2[\"Message\"].fillna(\"no comment\")\n        validation_size = validation_size   #by default it is 0.1\n        # splitting train:dev -->  9:1 so train consist of 90 percent and validation set consist of 10 percent of entire training data \n        #Note : This validation_size is configurable and can be changed later.\n        self.X_train, self.X_valid, self.Y_train, self.Y_valid = train_test_split(self.train, self.y, test_size = validation_size)\n        # Lowering all the comments of training, validation and test data let callled it as raw.\n        self.raw_text_train = self.X_train[self.tweet_column].str.lower()\n        self.raw_text_valid = self.X_valid[self.tweet_column].str.lower()\n        if self.model_Type != \"Spam-Detection\" :\n            self.raw_test_valid = self.test[self.tweet_column].str.lower()\n        return\n\n    def tokenizer(self):\n            '''\n            Input : raw train and dev set along with in-rawed train and dev set.\n            --------------------------------------------------------------------------------\n            Output: tokenizer object along with padded and sequenced training and validation dataset\n            '''\n            # Article for better undrstanding of Tokenizer : https://machinelearningknowledge.ai/keras-tokenizer-tutorial-with-examples-for-fit_on_texts-texts_to_sequences-texts_to_matrix-sequences_to_matrix/\n            #Tokeinzing the raw training set\n            self.tk.fit_on_texts(self.raw_text_train)\n            print(self.raw_text_train.shape )\n            self.X_train[self.tweet_column] = self.tk.texts_to_sequences(self.raw_text_train)\n            self.X_valid[self.tweet_column] = self.tk.texts_to_sequences(self.raw_text_valid)\n            self.X_train = pad_sequences(self.X_train[self.tweet_column], maxlen = self.max_len)\n            self.X_valid = pad_sequences(self.X_valid[self.tweet_column], maxlen = self.max_len)\n            if self.model_Type != \"Spam-Detection\" :\n                self.test[self.tweet_column] = self.tk.texts_to_sequences(self.raw_test_valid )\n                self.test = pad_sequences(self.test[self.tweet_column], maxlen = self.max_len) #test.comment_seq\n            return\n    \n    def get_coefs(self,word,*arr): \n        '''\n        Creating Embeeding Index which can help further to create embedding matrix for the words in our training dataset vocabulary.\n        This Ebedding index is created from the fastText or Glove.\n        '''\n        return word, np.asarray(arr, dtype='float32')\n    \n    \n    def embeeding_Index_Builder(self, embedding_path):\n        '''\n        Embedding Index correpsonding to embeddding Path\n        Input : embeddig path \n        ----------------------\n        Output : embedding Index\n        '''\n        embedding_index = dict(self.get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))\n        return embedding_index\n\n    def embeeding_Matrix_Builder(self,embedding_index ):\n        '''\n        Input : tokenizer object , with maximum features and embedding size along with fastText and Glove Embedding Index for building Embeeding Matrix\n        ----------------------------------------------------------------------------------------------------------------------------------------------\n        Output: embedding matix corresponding to FastText and Glove\n        '''\n        # Preparing Our Embeeding matrix from Embedding Index from glove or fastText or any other index. \n        damword_index = self.tk.word_index\n        nb_words = min(self.max_features, len(damword_index))\n        embedding_matrix = np.zeros((nb_words+1, self.embed_size))\n        for word, i in damword_index.items():\n            if i >= self.max_features: continue\n            embedding_vector = embedding_index.get(word)\n            if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n        return embedding_matrix\n    \n    def save_embeeding_index_or_matrix_as_csv(self, embedding_index_or_matrix, arrayType=\"index\", embeddingType=\"FastText\"):\n        # save numpy array embeeding_index as csv file\n        # define data\n        if arrayType!=\"index\":\n            data = copy.deepcopy(embedding_index_or_matrix)\n            # save to csv file\n            data = data.ravel()\n            np.savetxt(f'embedding_{arrayType}_{embeddingType}.csv', data, delimiter=',')\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"wb\")\n            pickle.dump(embedding_index_or_matrix, a_file)\n            a_file.close() \n        \n    def load_embedding_index_or_matrix_from_csv(self, arrayType=\"index\", embeddingType=\"FastText\"):\n        # load numpy array  embeeding_index from csv file\n        # load array\n        if arrayType!=\"index\":\n            data = np.loadtxt(f'embedding_{arrayType}_{embeddingType}.csv', delimiter=',')\n            reshaped_data = None\n\n            if embeddingType==\"FastText\" :\n#                 if arrayType==\"index\":\n                reshaped_data = np.reshape(data,self.embedding_index_fastText_shape )\n#                 else:\n#                     reshaped_data = np.reshape(data,self.embedding_matrix_fastText_shape )\n            elif embeddingType==\"Glove\":\n#                 if arrayType==\"index\":\n                reshaped_data = np.reshape(data,self.embedding_index_glove_shape )\n#                 else:\n#                     reshaped_data = np.reshape(data,self.embedding_matrix_glove_shape )\n            # print the array\n            return reshaped_data\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"rb\")\n            output = pickle.load(a_file)\n            return output\n\n            \n    \n    def save_embeeding_index_or_matrix_as_binary(self, embedding_index_or_matrix , arrayType=\"index\", embeddingType=\"FastText\"):\n        # save numpy array embeeding_index as binary file npy\n        # define data\n        if arrayType!=\"index\":\n            np.save(f'embedding_{arrayType}_{embeddingType}.npy', embedding_index_or_matrix )\n            return\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"wb\")\n            pickle.dump(embedding_index_or_matrix, a_file)\n            a_file.close() \n        \n    def load_embedding_index_or_matrix_from_binary(self, arrayType=\"index\", embeddingType=\"FastText\"):\n        # load numpy array  embeeding_index from npy file\n        # load array\n        if arrayType!=\"index\":\n            data = np.load(f'embedding_{arrayType}_{embeddingType}.csv')\n            return data\n        else:\n            a_file = open(f'embedding_{arrayType}_{embeddingType}.pkl', \"rb\")\n            output = pickle.load(a_file)\n            return output\n\n\n    def preprocessing(self, \n                      validation_size=0.1,\n                      embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\",\n                      embedding_path_glove =\"../input/glove840b300dtxt/glove.840B.300d.txt\",\n                      isEmbeddingIndexFileSaved     =False,\n                      isEmbeddingMatrixFileSaved    = False,\n                      wantToSaveEmbeedingIndexFile  = False,\n                      wantToSaveEmbeedingMatrixFile = False ):\n        self.build_train_test_dev_set()\n        print('Building Trainning and Testing is Done.')\n        self.train_test_splitter(validation_size)\n        print('Spliting Trainning and Testing is Done.')\n        self.tokenizer()\n        print('Tokenizing is Done.')\n        if not isEmbeddingIndexFileSaved :\n            self.embedding_index_fastText = self.embeeding_Index_Builder(embedding_path_fastText)\n            print('Embeeding Index for Fasttext is Done.')\n            self.embedding_index_glove = self.embeeding_Index_Builder(embedding_path_glove)\n            print('Embeeding Index for Glove is Done.')\n            if wantToSaveEmbeedingIndexFile:\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_index_fastText  , arrayType=\"index\", embeddingType=\"FastText\")\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_index_glove  , arrayType=\"index\", embeddingType=\"Glove\")\n        else:\n            self.embedding_index_fastText  = self.load_embedding_index_or_matrix_from_binary(arrayType=\"index\", embeddingType=\"FastText\")\n            self.embedding_index_glove  = self.load_embedding_index_or_matrix_from_binary(arrayType=\"index\", embeddingType=\"Glove\")\n#         self.embedding_index_fastText_shape = self.embedding_index_fastText.shape\n#         self.embedding_index_glove_shape = self.embedding_index_glove.shape\n        \n        if not isEmbeddingMatrixFileSaved :\n            self.embedding_matrix_fastText = self.embeeding_Matrix_Builder( self.embedding_index_fastText )\n            print(f'Embedding Matrix for FastText is Done., with it\\'s shape as {self.embedding_matrix_fastText_shape}')\n            self.embedding_matrix_glove = self.embeeding_Matrix_Builder( self.embedding_index_glove )\n            print(f'Embedding Matrix for Glove is Done with shape as { self.embedding_matrix_glove_shape}')\n            if  wantToSaveEmbeedingMatrixFile:\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_matrix_fastText , arrayType=\"matrix\", embeddingType=\"FastText\")\n                self.save_embeeding_index_or_matrix_as_binary(self.embedding_matrix_glove   , arrayType=\"matrix\", embeddingType=\"Glove\")\n        else:\n            self.embedding_matrix_fastText  = self.load_embedding_index_or_matrix_from_binary(arrayType=\"matrix\", embeddingType=\"FastText\")\n            self.embedding_matrix_glove     = self.load_embedding_index_or_matrix_from_binary(arrayType=\"matrix\", embeddingType=\"Glove\")\n#         self.embedding_matrix_fastText_shape = self.embedding_matrix_fastText.shape\n#         self.embedding_matrix_glove_shape =  self.embedding_matrix_glove.shape \n        return\n    \n#######################################################################################################################################################\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:13:20.025284Z","iopub.execute_input":"2022-02-27T16:13:20.025566Z","iopub.status.idle":"2022-02-27T16:13:20.076852Z","shell.execute_reply.started":"2022-02-27T16:13:20.025537Z","shell.execute_reply":"2022-02-27T16:13:20.076144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ML_Model :\n    def __init__(self, \n                 ModelBaseInstance = Preprocessor( embed_size = 300, \n                                           max_features = 130000, \n                                           max_len = 220, \n                                           model_Type = \"Spam-Detection\"),\n#                  embed_size = 300, \n#                  max_features = 130000, \n#                  max_len = 220, \n#                  model_Type = \"Spam-Detection\", \n                 file_path = \"1\",\n                 n_multiClassificationClasses = 1 ,# if Inappropriate then 6 as they are : \"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"\n                 *args, **kwargs):  # for file_path just pass which idea/framework on which this Model is based upon\n#         super(Preprocessor, self).__init__()\n#         super().__init__( embed_size = 300, \n#                           max_features = 130000, \n#                           max_len = 220, \n#                           model_Type = \"Spam-Detection\")\n        self.modelBase = ModelBaseInstance\n        self.model = None\n        self.history = None\n        self.framework_idea = file_path \n        self.file_path = \"best_model_\" + \"FrameWork\" + self.framework_idea + \"_\" + self.modelBase.model_Type  + \".hdf5\" \n        self.check_point = ModelCheckpoint(self.file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n        self.ra_val = None\n        #Allowing early stopping\n        self.early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n        self.n_output_nuerons = n_multiClassificationClasses\n        \n    def change_idea_for_same_object(self,change_idea_to=\"2\", automatic_train = False, *args, **kwargs):\n        earlier_idea = self.framework_idea \n        self.framework_idea = change_idea_to\n        self.file_path = \"best_model_\" + \"FrameWork\" + self.framework_idea + \"_\" + self.modelBase.model_Type + \".hdf5\" \n        self.check_point = ModelCheckpoint(self.file_path, monitor = \"val_loss\", verbose = 1, save_best_only = True, mode = \"min\")\n        print(f\"Framework is changeed succesfully \\n Idea/Frameowkr earlier :  {earlier_idea} \\n Idea/Framework Now {self.framework_idea } : \")\n        print(\"\\n\\n PS: This method will keep in handy when you want to test for multiple idea without doing preprocessing step again.\")\n        # TO-DO  allo training auto to be done for user given parameters\n        if automatic_train:\n            print(f\"Note: The training is requested to be done AUTOMATICALLY as automatic_train flag is {automatic_train}, Note:  This training will be done on default parameters \\n i.e lr = 0.0, \\n lr_d = 0.0, \\n units = 0, \\n dr = 0.0, \\n epochs=10.\")\n            print('OR The parameters which was set for earlier IDEA/FRAMEWORK')\n            self.train_Model()\n        else:\n            print(\"\\t Note : WE NEED TO RE-TRAINED THE MODEL.\\n\\n \\t For Help :: USE METHOD --> train_Model for this in order to train the model on new Idea/Framework. \\n \\t Not training automatically as Automatic train Flag is off.\")\n        return\n    \n    def roc_Auc_Valuation(self):\n        self.ra_val = RocAucEvaluation(validation_data=(self.modelBase.X_valid, self.modelBase.Y_valid), interval = 1)\n        return\n        \n    def build_model_framework1(self, lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n        inp = Input(shape = (self.modelBase.max_len,))\n#         x_fastText = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n#         x_glove = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n        x_fastText = Embedding(self.modelBase.embedding_matrix_fastText.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n        x_glove = Embedding(self.modelBase.embedding_matrix_glove.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n        \n    \n    #Drop-Out Layer\n        x1_fastText = SpatialDropout1D(dr)(x_fastText)\n        x1_glove = SpatialDropout1D(dr)(x_glove)\n        #BI-LSTM BRANCH\n        x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #BI-GRU BRNACH\n        x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n        #Bi-listm\n        x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n        x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n        x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n        #concatenating\n        x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n\n        x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n        x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n        x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n        #concatenating\n        x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n        #Bi-gru\n        x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n        x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n        x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n        #concatenating\n        x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n        x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n        x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n        x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n        #concatenating\n        x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n        #Con-Catenating Bi-Lstm branch\n        x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n        #Con-Catenating Bi-Gru branch\n        x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n        #ConCatenating Bi-LSTM and Bi-GRU Branch\n        x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n        #Passing concatenated output to dense network\n    #     xxxx = Dense(8, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    #     xxx = Dense(4, activation = \"sigmoid\")(xxxx)\n    #     xx = Dense(2, activation = \"sigmoid\")(xx)\n    #     x = Dense(1, activation = \"sigmoid\")(xx) \n        \n#         if self.model_Type != \"Spam-Detection\" :\n#             assert self.n_output_nuerons==6\n#         else:\n#             assert self.n_output_nuerons==1\n\n        print(self.n_output_nuerons)\n            \n        x = Dense(self.n_output_nuerons, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n        self.model = Model(inputs = inp, outputs = x)\n        self.model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    #     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    \n#         print(\"*************************************************\")\n#         print(f\"Y_train's size/shape  ={self.modelBase.Y_train.shape} \")\n#         print(f\"Y_valid's size/shape  ={self.modelBase.Y_valid.shape} \")  \n        \n        self.history = self.model.fit(self.modelBase.X_train, self.modelBase.Y_train, batch_size = 128, epochs = epochs, validation_data = (self.modelBase.X_valid, self.modelBase.Y_valid), \n                            verbose = 1, callbacks = [self.ra_val, self.check_point, self.early_stop])\n        self.model = load_model(self.file_path)\n        return\n        \n    def build_model_framework2(self,lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n        inp = Input(shape = (self.modelBase.max_len,))\n#         x_fastText = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n#         x_glove = Embedding( self.max_features, self.embed_size, weights = [self.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n\n        x_fastText = Embedding(self.modelBase.embedding_matrix_fastText.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_fastText], trainable = False)(inp)# Let this layer be the FatText input embedding\n        x_glove = Embedding(self.modelBase.embedding_matrix_glove.shape[0], self.modelBase.embed_size, weights = [self.modelBase.embedding_matrix_glove], trainable = False)(inp)# Let this layer be the Glove input embedding\n       \n    #Drop-Out Layer\n        x1_fastText = SpatialDropout1D(dr)(x_fastText)\n        x1_glove = SpatialDropout1D(dr)(x_glove)\n        #BI-LSTM BRANCH\n        x_glove_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_lstm = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #BI-GRU BRNACH\n        x_glove_gru = Bidirectional(GRU(units, return_sequences = True))(x1_glove)\n        x_fastText_gru = Bidirectional(GRU(units, return_sequences = True))(x1_fastText)\n        #Convolutional+Pooling Layer This is Optional Can be commnented later if required for testing purposes\n        #Bi-listm\n        x_glove_lstm_conv           = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_lstm)\n        x_glove_lstm_conv_avgPool   = GlobalAveragePooling1D()(x_glove_lstm_conv)\n        x_glove_lstm_conv_maxPool   = GlobalMaxPooling1D()(x_glove_lstm_conv)\n        #concatenating\n        x_glove_lstm_conv_pooled    = concatenate([x_glove_lstm_conv_avgPool, x_glove_lstm_conv_maxPool])\n\n        x_fastText_lstm_conv        = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_lstm)\n        x_fastText_lstm_conv_avgPool= GlobalAveragePooling1D()(x_fastText_lstm_conv)\n        x_fastText_lstm_conv_maxPool= GlobalMaxPooling1D()(x_fastText_lstm_conv)\n        #concatenating\n        x_fastText_lstm_conv_pooled = concatenate([x_fastText_lstm_conv_avgPool, x_fastText_lstm_conv_maxPool])\n        #Bi-gru\n        x_glove_gru_conv            = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_glove_gru)\n        x_glove_gru_conv_avgPool    = GlobalAveragePooling1D()(x_glove_gru_conv)\n        x_glove_gru_conv_maxPool    = GlobalMaxPooling1D()(x_glove_gru_conv)\n        #concatenating\n        x_glove_gru_conv_pooled     = concatenate([x_glove_gru_conv_avgPool, x_glove_gru_conv_maxPool])\n\n        x_fastText_gru_conv         = Conv1D(int(units/2), kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x_fastText_gru)\n        x_fastText_gru_conv_avgPool = GlobalAveragePooling1D()(x_fastText_gru_conv)\n        x_fastText_gru_conv_maxPool = GlobalMaxPooling1D()(x_fastText_gru_conv)\n        #concatenating\n        x_fastText_gru_conv_pooled  = concatenate([x_fastText_gru_conv_avgPool, x_fastText_gru_conv_maxPool])\n        #Con-Catenating Bi-Lstm branch\n        x_lstm_conv_pooled = concatenate([x_glove_lstm_conv_pooled,  x_fastText_lstm_conv_pooled])\n        #Con-Catenating Bi-Gru branch\n        x_gru_conv_pooled = concatenate([x_glove_gru_conv_pooled,  x_fastText_gru_conv_pooled])\n        #ConCatenating Bi-LSTM and Bi-GRU Branch\n        x_lstm_gru_concatenated = concatenate([x_lstm_conv_pooled, x_gru_conv_pooled])\n        #Passing concatenated output to dense network\n    #     xxxx = Dense(8, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n    #     xxx = Dense(4, activation = \"sigmoid\")(xxxx)\n    #     xx = Dense(2, activation = \"sigmoid\")(xxx)\n    #     x = Dense(1, activation = \"sigmoid\")(xx)\n    \n        print(self.n_output_nuerons)\n\n        x = Dense(self.n_output_nuerons, activation = \"sigmoid\")(x_lstm_gru_concatenated)\n        self.model = Model(inputs = inp, outputs = x)\n        self.model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    #     model.compile(loss = \"binary_crossentropy\", optimizer = adam_v2.Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n        self.history = self.model.fit(self.modelBase.X_train, self.modelBase.Y_train, batch_size = 128, epochs = epochs, validation_data = (self.modelBase.X_valid, self.modelBase.Y_valid), \n                            verbose = 1, callbacks = [self.ra_val, self.check_point, self.early_stop])\n        self.model = load_model(self.file_path)\n        return \n    \n    def build_model_framework3(self,lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0, epochs=10):\n        pass\n    \n    def build_model(self, lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 30):\n        self.roc_Auc_Valuation()\n        if self.framework_idea == \"1\":\n            self.build_model_framework1( lr, lr_d , units, dr ,epochs)\n        elif self.framework_idea == \"2\":\n            self.build_model_framework2( lr, lr_d , units, dr ,epochs)\n        else : \n            self.build_model_framework3( lr, lr_d , units, dr ,epochs)\n        \n    def train_Model(self, lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 30):\n        #For training use this member function\n        print(\"TRAINING STARTED\")\n        self.build_model(lr , lr_d, units, dr ,epochs)\n        print(\"TRAINING COMPLETED\")\n    \n    def get_accuracy_for_validation_set(self):\n        return self.prediction(self.modelBase.X_valid, self.modelBase.Y_valid)\n        \n    def get_accuracy_for_training_set(self):\n        return self.prediction(self.modelBase.X_train, self.modelBase.Y_train)\n         \n    def Plot(self, string): # example Object.Plot(history, \"accuracy\")  or Object.Plot(history, \"loss\")\n        plt.plot(self.history.history[string])\n        plt.plot(self.history.history['val_' + string])\n        plt.xlabel(\"EPOCHS\")\n        plt.ylabel(string)\n        plt.legend([string, 'val_' + string ])\n        plt.savefig(string + \"_framework-\" + self.framework_idea  +'_' + self.modelBase.model_Type  + '_'+'.png')\n        plt.show()       \n        print(f\"###### DONE PLOTTING FOR IDEA - {self.framework_idea} ########\")\n                    \n    def prediction(self,dataset, y_actual,on_the_fly=0 ): # On the fly is for those data that is comimg on the fly from any tweet.\n        if on_the_fly == 1 :\n            pass\n        y_pred_validation = self.model.predict(dataset, verbose=1)\n        score_validation = roc_auc_score(y_actual, y_pred_validation)\n        print(f\"\\n ROC-AUC - ON Validation Dataset - score: {round(score_validation,5)*100}%\")\n        return y_pred_validation\n    \n##############################################################################################################################################################","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:13:26.16506Z","iopub.execute_input":"2022-02-27T16:13:26.165324Z","iopub.status.idle":"2022-02-27T16:13:26.216138Z","shell.execute_reply.started":"2022-02-27T16:13:26.165294Z","shell.execute_reply":"2022-02-27T16:13:26.215459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Inappropriate Content Detection**","metadata":{}},{"cell_type":"code","source":"%%time\nInappContentModel1Preprocessor = Preprocessor( embed_size = 300, \n                                               max_features = 130000, \n                                               max_len = 220, \n                                               model_Type = \"Inappropriate-Content-Detection\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T13:56:13.775165Z","iopub.execute_input":"2022-02-27T13:56:13.775883Z","iopub.status.idle":"2022-02-27T13:56:13.783038Z","shell.execute_reply.started":"2022-02-27T13:56:13.775844Z","shell.execute_reply":"2022-02-27T13:56:13.782148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nInappContentModel1Preprocessor.preprocessing( validation_size=0.1,\n                                  embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\",\n                                  embedding_path_glove =\"../input/glove840b300dtxt/glove.840B.300d.txt\" ,\n                                  isEmbeddingIndexFileSaved     =False,\n                                  isEmbeddingMatrixFileSaved    = False,\n                                  wantToSaveEmbeedingIndexFile  = False,\n                                  wantToSaveEmbeedingMatrixFile = False )","metadata":{"execution":{"iopub.status.busy":"2022-02-27T13:56:43.407326Z","iopub.execute_input":"2022-02-27T13:56:43.407905Z","iopub.status.idle":"2022-02-27T14:03:16.682944Z","shell.execute_reply.started":"2022-02-27T13:56:43.407868Z","shell.execute_reply":"2022-02-27T14:03:16.682088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(InappContentModel1Preprocessor.X_valid)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# InappContentModel1Preprocessor.test.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-27T12:11:21.202269Z","iopub.execute_input":"2022-02-27T12:11:21.202813Z","iopub.status.idle":"2022-02-27T12:11:21.208239Z","shell.execute_reply.started":"2022-02-27T12:11:21.202777Z","shell.execute_reply":"2022-02-27T12:11:21.207496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ******************************************************","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nInappContentModel1 = ML_Model( InappContentModel1Preprocessor,\n                               file_path = \"1\",\n                               n_multiClassificationClasses = 6 )","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:03:16.685857Z","iopub.execute_input":"2022-02-27T14:03:16.686063Z","iopub.status.idle":"2022-02-27T14:03:16.693908Z","shell.execute_reply.started":"2022-02-27T14:03:16.686036Z","shell.execute_reply":"2022-02-27T14:03:16.693052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nInappContentModel1.train_Model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 3 )\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:03:16.695213Z","iopub.execute_input":"2022-02-27T14:03:16.695475Z","iopub.status.idle":"2022-02-27T14:13:53.778245Z","shell.execute_reply.started":"2022-02-27T14:03:16.695439Z","shell.execute_reply":"2022-02-27T14:13:53.777539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(InappContentModel1.n_output_nuerons )\nprint(InappContentModel1.modelBase.embedding_matrix_glove.shape[0])\nprint(InappContentModel1.modelBase.max_features)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:13:53.782788Z","iopub.execute_input":"2022-02-27T14:13:53.784996Z","iopub.status.idle":"2022-02-27T14:13:53.794614Z","shell.execute_reply.started":"2022-02-27T14:13:53.784954Z","shell.execute_reply":"2022-02-27T14:13:53.793931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_pred_train = InappContentModel1.get_accuracy_for_training_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:13:53.799222Z","iopub.execute_input":"2022-02-27T14:13:53.80133Z","iopub.status.idle":"2022-02-27T14:16:20.30085Z","shell.execute_reply.started":"2022-02-27T14:13:53.801292Z","shell.execute_reply":"2022-02-27T14:16:20.299029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_pred_valid  = InappContentModel1.get_accuracy_for_validation_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:16:20.302097Z","iopub.execute_input":"2022-02-27T14:16:20.302376Z","iopub.status.idle":"2022-02-27T14:16:40.85201Z","shell.execute_reply.started":"2022-02-27T14:16:20.302325Z","shell.execute_reply":"2022-02-27T14:16:40.851201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InappContentModel1.Plot( \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:16:40.853766Z","iopub.execute_input":"2022-02-27T14:16:40.854306Z","iopub.status.idle":"2022-02-27T14:16:41.273063Z","shell.execute_reply.started":"2022-02-27T14:16:40.854263Z","shell.execute_reply":"2022-02-27T14:16:41.272416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"InappContentModel1.Plot( \"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:16:41.276766Z","iopub.execute_input":"2022-02-27T14:16:41.278635Z","iopub.status.idle":"2022-02-27T14:16:41.570864Z","shell.execute_reply.started":"2022-02-27T14:16:41.278592Z","shell.execute_reply":"2022-02-27T14:16:41.570117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# CHECKING FOR IDEA 2 BY SWITCHING \n\nInappContentModel1.change_idea_for_same_object( change_idea_to = \"2\", automatic_train = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:16:41.57213Z","iopub.execute_input":"2022-02-27T14:16:41.572776Z","iopub.status.idle":"2022-02-27T14:40:18.144656Z","shell.execute_reply.started":"2022-02-27T14:16:41.572737Z","shell.execute_reply":"2022-02-27T14:40:18.143853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2\ny_pred_train = InappContentModel1.get_accuracy_for_training_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:40:18.14724Z","iopub.execute_input":"2022-02-27T14:40:18.147806Z","iopub.status.idle":"2022-02-27T14:43:42.46422Z","shell.execute_reply.started":"2022-02-27T14:40:18.147764Z","shell.execute_reply":"2022-02-27T14:43:42.463418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2 \ny_pred_valid  = InappContentModel1.get_accuracy_for_validation_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:43:42.465633Z","iopub.execute_input":"2022-02-27T14:43:42.465914Z","iopub.status.idle":"2022-02-27T14:44:03.00186Z","shell.execute_reply.started":"2022-02-27T14:43:42.465876Z","shell.execute_reply":"2022-02-27T14:44:03.001048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2\nInappContentModel1.Plot( \"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:44:03.003279Z","iopub.execute_input":"2022-02-27T14:44:03.003563Z","iopub.status.idle":"2022-02-27T14:44:03.253486Z","shell.execute_reply.started":"2022-02-27T14:44:03.003526Z","shell.execute_reply":"2022-02-27T14:44:03.252422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2 \nInappContentModel1.Plot( \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T14:44:03.497612Z","iopub.execute_input":"2022-02-27T14:44:03.498441Z","iopub.status.idle":"2022-02-27T14:44:03.738667Z","shell.execute_reply.started":"2022-02-27T14:44:03.498401Z","shell.execute_reply":"2022-02-27T14:44:03.737971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SPAM detection**\n","metadata":{}},{"cell_type":"code","source":"%%time\nspamDetectionModel1Preprocessor = Preprocessor( embed_size = 300, \n                                               max_features = 130000, \n                                               max_len = 220, \n                                               model_Type = \"Spam-Detection\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:13:53.091639Z","iopub.execute_input":"2022-02-27T16:13:53.092351Z","iopub.status.idle":"2022-02-27T16:13:53.097554Z","shell.execute_reply.started":"2022-02-27T16:13:53.092313Z","shell.execute_reply":"2022-02-27T16:13:53.096831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nspamDetectionModel1Preprocessor.preprocessing( validation_size=0.1,\n                                  embedding_path_fastText = \"../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec\",\n                                  embedding_path_glove =\"../input/glove840b300dtxt/glove.840B.300d.txt\" ,\n                                  isEmbeddingIndexFileSaved     =False,\n                                  isEmbeddingMatrixFileSaved    = False,\n                                  wantToSaveEmbeedingIndexFile  = False,\n                                  wantToSaveEmbeedingMatrixFile = False )","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:13:55.501561Z","iopub.execute_input":"2022-02-27T16:13:55.502039Z","iopub.status.idle":"2022-02-27T16:19:40.270078Z","shell.execute_reply.started":"2022-02-27T16:13:55.502005Z","shell.execute_reply":"2022-02-27T16:19:40.269235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nspamDetectionModel1 = ML_Model( spamDetectionModel1Preprocessor,\n                               file_path = \"1\",\n                               n_multiClassificationClasses = 1 )","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:22:34.125815Z","iopub.execute_input":"2022-02-27T16:22:34.126075Z","iopub.status.idle":"2022-02-27T16:22:34.131948Z","shell.execute_reply.started":"2022-02-27T16:22:34.126046Z","shell.execute_reply":"2022-02-27T16:22:34.130973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nspamDetectionModel1.train_Model(lr = 1e-3, lr_d = 0, units = 112, dr = 0.2,epochs = 3 )","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:22:36.755106Z","iopub.execute_input":"2022-02-27T16:22:36.755388Z","iopub.status.idle":"2022-02-27T16:23:32.418932Z","shell.execute_reply.started":"2022-02-27T16:22:36.755358Z","shell.execute_reply":"2022-02-27T16:23:32.417434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ny_pred_valid  = spamDetectionModel1.get_accuracy_for_validation_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:23:32.420605Z","iopub.execute_input":"2022-02-27T16:23:32.420805Z","iopub.status.idle":"2022-02-27T16:23:35.580771Z","shell.execute_reply.started":"2022-02-27T16:23:32.42078Z","shell.execute_reply":"2022-02-27T16:23:35.580006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spamDetectionModel1.Plot( \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:23:35.582124Z","iopub.execute_input":"2022-02-27T16:23:35.582572Z","iopub.status.idle":"2022-02-27T16:23:35.889317Z","shell.execute_reply.started":"2022-02-27T16:23:35.582535Z","shell.execute_reply":"2022-02-27T16:23:35.888572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spamDetectionModel1.Plot( \"accuracy\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:23:35.891473Z","iopub.execute_input":"2022-02-27T16:23:35.891929Z","iopub.status.idle":"2022-02-27T16:23:36.156734Z","shell.execute_reply.started":"2022-02-27T16:23:35.891891Z","shell.execute_reply":"2022-02-27T16:23:36.155986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# CHECKING FOR IDEA 2 BY SWITCHING \nspamDetectionModel1.change_idea_for_same_object( change_idea_to = \"2\", automatic_train = True)","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:23:36.157911Z","iopub.execute_input":"2022-02-27T16:23:36.15874Z","iopub.status.idle":"2022-02-27T16:28:12.021592Z","shell.execute_reply.started":"2022-02-27T16:23:36.158695Z","shell.execute_reply":"2022-02-27T16:28:12.020736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2\ny_pred_train = spamDetectionModel1.get_accuracy_for_training_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:28:12.022815Z","iopub.execute_input":"2022-02-27T16:28:12.02306Z","iopub.status.idle":"2022-02-27T16:28:25.657961Z","shell.execute_reply.started":"2022-02-27T16:28:12.023023Z","shell.execute_reply":"2022-02-27T16:28:25.65712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Note this prediction is  FOR IDEA 2 \ny_pred_valid  = spamDetectionModel1.get_accuracy_for_validation_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:28:25.659305Z","iopub.execute_input":"2022-02-27T16:28:25.659572Z","iopub.status.idle":"2022-02-27T16:28:26.97196Z","shell.execute_reply.started":"2022-02-27T16:28:25.659537Z","shell.execute_reply":"2022-02-27T16:28:26.9711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2 \nspamDetectionModel1.Plot( \"loss\")","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:28:26.973515Z","iopub.execute_input":"2022-02-27T16:28:26.973788Z","iopub.status.idle":"2022-02-27T16:28:27.395089Z","shell.execute_reply.started":"2022-02-27T16:28:26.973749Z","shell.execute_reply":"2022-02-27T16:28:27.394432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Note this prediction is  FOR IDEA 2\nspamDetectionModel1.Plot( \"accuracy\")\n\n%%time\n# Note this prediction is  FOR IDEA 2\ny_pred_train = InappContentModel1.get_accuracy_for_training_set()","metadata":{"execution":{"iopub.status.busy":"2022-02-27T16:28:27.398776Z","iopub.execute_input":"2022-02-27T16:28:27.399377Z","iopub.status.idle":"2022-02-27T16:28:27.730125Z","shell.execute_reply.started":"2022-02-27T16:28:27.399337Z","shell.execute_reply":"2022-02-27T16:28:27.728842Z"},"trusted":true},"execution_count":null,"outputs":[]}]}